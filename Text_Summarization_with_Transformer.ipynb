{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIuBwg-7_XFC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregando o dataset utilizado"
      ],
      "metadata": {
        "id": "1YtJfbUCdXGi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgKsZDOS_5it",
        "outputId": "e5b546ae-4720-43e7-a96b-0f99f3efa9f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.19.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"cnn_dailymail\", \"3.0.0\")"
      ],
      "metadata": {
        "id": "nd0towOx_0Le",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1226c8a5-2d01-42b5-b9dd-1700ae8f4fec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Criando o dataframe"
      ],
      "metadata": {
        "id": "qhJ9zYxKdapy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convertendo o split de treino para um DataFrame\n",
        "df_train = pd.DataFrame(dataset['train'])\n",
        "\n",
        "# Se quiser unir treino + validação + teste (opcional)\n",
        "df_val = pd.DataFrame(dataset['validation'])\n",
        "df_test = pd.DataFrame(dataset['test'])\n",
        "\n",
        "# Junta tudo em um único DataFrame\n",
        "df = pd.concat([df_train, df_val, df_test], ignore_index=True)\n",
        "\n",
        "# Renomeia a coluna 'highlights' para 'summary'\n",
        "df.rename(columns={'highlights': 'summary'}, inplace=True)\n",
        "\n",
        "# Dataset para testes\n",
        "df_final_testes = pd.concat([df_train, df_val, df_test], ignore_index=True)\n",
        "df_final_testes.rename(columns={'highlights': 'summary'}, inplace=True)\n",
        "\n",
        "# Mostra algumas amostras\n",
        "\n",
        "print(df.columns)\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "1L_KpeajAbGJ",
        "outputId": "f941bbd5-f5bc-4c0e-9346-fcdbc1303d81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['article', 'summary', 'id'], dtype='object')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             article  \\\n",
              "0  LONDON, England (Reuters) -- Harry Potter star...   \n",
              "1  Editor's note: In our Behind the Scenes series...   \n",
              "2  MINNEAPOLIS, Minnesota (CNN) -- Drivers who we...   \n",
              "3  WASHINGTON (CNN) -- Doctors removed five small...   \n",
              "4  (CNN)  -- The National Football League has ind...   \n",
              "\n",
              "                                             summary  \\\n",
              "0  Harry Potter star Daniel Radcliffe gets £20M f...   \n",
              "1  Mentally ill inmates in Miami are housed on th...   \n",
              "2  NEW: \"I thought I was going to die,\" driver sa...   \n",
              "3  Five small polyps found during procedure; \"non...   \n",
              "4  NEW: NFL chief, Atlanta Falcons owner critical...   \n",
              "\n",
              "                                         id  \n",
              "0  42c027e4ff9730fbb3de84c1af0d2c506e41c3e4  \n",
              "1  ee8871b15c50d0db17b0179a6d2beab35065f1e9  \n",
              "2  06352019a19ae31e527f37f7571c6dd7f0c5da37  \n",
              "3  24521a2abb2e1f5e34e6824e0f9e56904a2b0e88  \n",
              "4  7fe70cc8b12fab2d0a258fababf7d9c6b5e1262a  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-afcaba99-d55d-4019-a76b-ccc2a0d38d5c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>summary</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>LONDON, England (Reuters) -- Harry Potter star...</td>\n",
              "      <td>Harry Potter star Daniel Radcliffe gets £20M f...</td>\n",
              "      <td>42c027e4ff9730fbb3de84c1af0d2c506e41c3e4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Editor's note: In our Behind the Scenes series...</td>\n",
              "      <td>Mentally ill inmates in Miami are housed on th...</td>\n",
              "      <td>ee8871b15c50d0db17b0179a6d2beab35065f1e9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MINNEAPOLIS, Minnesota (CNN) -- Drivers who we...</td>\n",
              "      <td>NEW: \"I thought I was going to die,\" driver sa...</td>\n",
              "      <td>06352019a19ae31e527f37f7571c6dd7f0c5da37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WASHINGTON (CNN) -- Doctors removed five small...</td>\n",
              "      <td>Five small polyps found during procedure; \"non...</td>\n",
              "      <td>24521a2abb2e1f5e34e6824e0f9e56904a2b0e88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(CNN)  -- The National Football League has ind...</td>\n",
              "      <td>NEW: NFL chief, Atlanta Falcons owner critical...</td>\n",
              "      <td>7fe70cc8b12fab2d0a258fababf7d9c6b5e1262a</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-afcaba99-d55d-4019-a76b-ccc2a0d38d5c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-afcaba99-d55d-4019-a76b-ccc2a0d38d5c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-afcaba99-d55d-4019-a76b-ccc2a0d38d5c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c3d0d219-1e2e-46b1-bec5-46d803937443\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c3d0d219-1e2e-46b1-bec5-46d803937443')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c3d0d219-1e2e-46b1-bec5-46d803937443 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Selecionando 40 mil amostras\n",
        "print(df.shape)\n",
        "df = df.sample(n=40000, random_state=42)\n",
        "print(df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lptCS65NMvtk",
        "outputId": "45bb646f-0e3b-4006-d7ef-8fe7a02d0f7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(311971, 3)\n",
            "(40000, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tokenizando os dados"
      ],
      "metadata": {
        "id": "nKi9H0_MdiQt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 329
        },
        "id": "-EV3tlAX_XFH",
        "outputId": "4b69dae1-253a-4268-dfeb-4acd314a588a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  article  \\\n",
              "214346  Former Manchester United striker Michael Owen ...   \n",
              "215595  Roy Hodgson will host a dinner for his England...   \n",
              "136749  By . Ryan Gorman . PUBLISHED: . 13:24 EST, 29 ...   \n",
              "45878   (Martha Stewart Living) -- It is incredible ho...   \n",
              "56340   (CNN) -- Former Argentina coach Diego Maradona...   \n",
              "\n",
              "                                                  summary  \\\n",
              "214346  Manchester United have won six of their last s...   \n",
              "215595  Roy Hodgson will assemble his England squad fo...   \n",
              "136749  Kontue Johnson, 21, was shot at least 14 times...   \n",
              "45878   Martha Stewart wanted to make child-safe decor...   \n",
              "56340   Diego Maradona will be the new coach of Dubai-...   \n",
              "\n",
              "                                              id  \\\n",
              "214346  a58b45d8f3cb1466b3da41bc32c735ca80e95182   \n",
              "215595  205d3a9f95e5ce8699ad05cdb1b5637d0a8a4163   \n",
              "136749  cb1ce04f821848c70f0c4865a65e9a27afc9f400   \n",
              "45878   576795a50c4edc651bfe6412faaf2f612a532f72   \n",
              "56340   09c8329cd1b793b9373d87140ca1fd9f2a762f8d   \n",
              "\n",
              "                                          text_tokenizado  \\\n",
              "214346  [<start>, former, manchester, united, striker,...   \n",
              "215595  [<start>, roy, hodgson, will, host, a, dinner,...   \n",
              "136749  [<start>, by, ., ryan, gorman, ., published, :...   \n",
              "45878   [<start>, (, martha, stewart, living, ), --, i...   \n",
              "56340   [<start>, (, cnn, ), --, former, argentina, co...   \n",
              "\n",
              "                                       summary_tokenizado  \n",
              "214346  [<start>, manchester, united, have, won, six, ...  \n",
              "215595  [<start>, roy, hodgson, will, assemble, his, e...  \n",
              "136749  [<start>, kontue, johnson, ,, 21, ,, was, shot...  \n",
              "45878   [<start>, martha, stewart, wanted, to, make, c...  \n",
              "56340   [<start>, diego, maradona, will, be, the, new,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b6b56902-7a93-4801-ab32-ae53936c1169\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>summary</th>\n",
              "      <th>id</th>\n",
              "      <th>text_tokenizado</th>\n",
              "      <th>summary_tokenizado</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>214346</th>\n",
              "      <td>Former Manchester United striker Michael Owen ...</td>\n",
              "      <td>Manchester United have won six of their last s...</td>\n",
              "      <td>a58b45d8f3cb1466b3da41bc32c735ca80e95182</td>\n",
              "      <td>[&lt;start&gt;, former, manchester, united, striker,...</td>\n",
              "      <td>[&lt;start&gt;, manchester, united, have, won, six, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215595</th>\n",
              "      <td>Roy Hodgson will host a dinner for his England...</td>\n",
              "      <td>Roy Hodgson will assemble his England squad fo...</td>\n",
              "      <td>205d3a9f95e5ce8699ad05cdb1b5637d0a8a4163</td>\n",
              "      <td>[&lt;start&gt;, roy, hodgson, will, host, a, dinner,...</td>\n",
              "      <td>[&lt;start&gt;, roy, hodgson, will, assemble, his, e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136749</th>\n",
              "      <td>By . Ryan Gorman . PUBLISHED: . 13:24 EST, 29 ...</td>\n",
              "      <td>Kontue Johnson, 21, was shot at least 14 times...</td>\n",
              "      <td>cb1ce04f821848c70f0c4865a65e9a27afc9f400</td>\n",
              "      <td>[&lt;start&gt;, by, ., ryan, gorman, ., published, :...</td>\n",
              "      <td>[&lt;start&gt;, kontue, johnson, ,, 21, ,, was, shot...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45878</th>\n",
              "      <td>(Martha Stewart Living) -- It is incredible ho...</td>\n",
              "      <td>Martha Stewart wanted to make child-safe decor...</td>\n",
              "      <td>576795a50c4edc651bfe6412faaf2f612a532f72</td>\n",
              "      <td>[&lt;start&gt;, (, martha, stewart, living, ), --, i...</td>\n",
              "      <td>[&lt;start&gt;, martha, stewart, wanted, to, make, c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56340</th>\n",
              "      <td>(CNN) -- Former Argentina coach Diego Maradona...</td>\n",
              "      <td>Diego Maradona will be the new coach of Dubai-...</td>\n",
              "      <td>09c8329cd1b793b9373d87140ca1fd9f2a762f8d</td>\n",
              "      <td>[&lt;start&gt;, (, cnn, ), --, former, argentina, co...</td>\n",
              "      <td>[&lt;start&gt;, diego, maradona, will, be, the, new,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b6b56902-7a93-4801-ab32-ae53936c1169')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b6b56902-7a93-4801-ab32-ae53936c1169 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b6b56902-7a93-4801-ab32-ae53936c1169');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-eab86bbf-c7ea-4cfb-ad6e-32c61a7ce220\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-eab86bbf-c7ea-4cfb-ad6e-32c61a7ce220')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-eab86bbf-c7ea-4cfb-ad6e-32c61a7ce220 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 40000,\n  \"fields\": [\n    {\n      \"column\": \"article\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39959,\n        \"samples\": [\n          \"By . Bianca London . PUBLISHED: . 09:42 EST, 22 June 2012 . | . UPDATED: . 09:42 EST, 22 June 2012 . Supermodel Stella Tennant became the new Givenchy girl in a euphoric rave-style shoot for their latest ad campaign. The French label's fall 2012 campaign captures a dancing Stella, thumping electro music and an exquisite collection of Givenchy clothes, of course. The fractured images of the model shimmying beneath a dark and stormy sky aim to capture the euphoric energy of a rave, according to creative director, Richard Tisci - whose shows often feature booming house music. Euphoric rave: Stella Tennant dances away to electronic music beneath a stormy sky in Givenchy's latest ad campaign . Tisci's ad was captured by acclaimed and respected photographers Mert and Marcus who are famous in the fashion world for their portraits of sophisticated and powerful women. As the latest member of the Givenchy gang, Stella is joined by Joan Smalls, as well as newcomers Stef van der Laan, Daniela Braga, and male models Simone Nobili, Jarrod Scott, and Rodrigo Braga. Lady in purple: Stella Tennant worked her best colour at the Scottish Fashion Awards this month . Styled by Carine Roitfield, the latest photos lend an air of grace and unmistakable perfection to Givenchy's campaign and show Stella donning a purple dress already on the target of various fashion critics. 'It is about happiness and the freedom of expressing yourself with your body. It shows a dynamic, happy and fun world, which is what fashion needs,' said Richard Tisci about his distinctive campaign. 'Stella represents modernity, elegance, . masculinity and femininity at the same time, together with a dynamic, . energetic beauty,' he said. The models will fill the pages of glossy magazines in September. Stella recently graced the red carpet at the seventh annual Scottish Fashion Awards, held at the Clyde Auditorium in Glasgow. The event, hosted by Alexa Chung, saw . Stella proving purple is her favourite colour in fitted purple and black . rippled dress, fishnet nights and on-trend quiffed hair. Tennant is a fashion favourite, she was . chosen to walk the runway for Shiatzy Chen, Chanel and is a muse of the . designer Karl Lagerfeld. She has also appeared in numerous . advertising campaigns, including Calvin Klein, Herm\\u00e8s, and Burberry and . has starred in L.K.Bennett's campaign photographed by Tim Walker.\",\n          \"By . Harriet Arkell . PUBLISHED: . 09:57 EST, 14 October 2013 . | . UPDATED: . 10:58 EST, 14 October 2013 . Adam Downworth, 32, of Stockport, was given 10 life sentences after being convicted of a string of rape and sexual assault charges . An office cleaner who hunted down and attacked young women walking home alone at night was given ten life sentences today. Serial rapist Adam Downworth, 32, cruised the streets in his Citroen Berlingo so he could deliberately spot and ambush lone victims who had been drinking with friends. After selecting his target, Downworth would park his van before stalking and creeping up on the women on secluded roads and public parks. He incapacitated them using throttling manoeuvres he learnt from his martial arts books before subjecting the victims to sadistic sexual attacks as they came round and pleading for mercy. One woman who begged Downworth to take her purse and mobile phone was told: 'Look at my eyes. 'It\\u2019s all about teaching little bitches like you that they can\\u2019t walk on the street on their own when there\\u2019s men like me about. 'It\\u2019s not about the money. If it was about money, I\\u2019d have took it by now.' Another victim suffered several facial fractures after being kicked about the head and raped twice. She feared she would die during a 30-minute ordeal as Downworth told her: 'You\\u2019re all dirty b******. No-one will look at you again.' Downworth claimed five victims during his 10-month reign of terror across Stockport and Manchester before being captured in September last year. Whilst he was on the loose, drunken and vulnerable women found walking alone at night were stopped and given lifts home by police in patrol cars to avoid them becoming his next victims. During a raid officers found a library of martial arts books at the home of Downworth\\u2019s mother including Secrets of the Ninja, The Invisible Ninja: Ancient Secrets of Surprise, and Knights of Darkness. Scroll down for video . Police found these books on ninja fighting techniques and forensics among others belonging to the rapist . One of Downworth's victims was attacked in Alexandra Park in the rapist's hometown of Stockport . Chapters on choking and strangling and how to stage surprise attacks were highlighted in pencil. One passage told how a combatant in a martial contest could be incapacitated in just three seconds. It emerged Downworth was also a Facebook troll who used a victim\\u2019s mobile phone to scour the social media site for other women so he could send them filthy messages. One read: 'Dya really fink ur so atraktive, ha. U dres like a s*** so just luk cheap like a hooker u don\\u2019t pay.' Today there were shouts from the public gallery at Minshull Street Crown Court, Manchester, of: 'Rot in hell' and 'I hope you die a slow death' as Downworth, of Brinnington, was ordered to serve a minimum of 23 years in jail. He was convicted of 13 charges including rape, attempted rape, assault by penetration and assault occasioning actual and grievous bodily harm. CCTV shows Downworth leaving his flat in Brinnington, Stockport, on his way to commit his final sex attack . Stills from the CCTV show Downworth leaving his home in the Stockport suburb and looking for his next victim . Rapist's sick library: Titles belonging to Downworth including Attacking Judo, Ground Fighting, and Grips . Police fear there may have been other victims who were too frightened to come forward. The court heard how victims suffered serious injuries and long-lasting psychological harm as a result of the attacks, in which Downworth would wear blue surgical gloves from his workplace to avoid his fingerprints being found at the scene of his crimes. Alaric Bassano, prosecuting said: 'On each of the occasions he cruised the streets in his works van seeking out vulnerable lone females in secluded locations. 'Once he had identified victims, he discreetly parked his van and pursued them on foot, either attacking them from behind or lying in wait until they crossed his path. 'A striking feature of these attacks is the use of gratuitous violence against his victims, violence beyond that necessity to fulfil his sexual purpose and seemingly unleashed simply to increase the suffering of the women. Alexandra Park in Stockport was one of the locations of his attacks - he also attacked women in Manchester . This CCTV still shows Downworth, 32, following his future victim along Nangreave Road in Stockport . Downworth, seen here following his intended prey, is now serving 10 life sentences for a string of sex crimes . Terrifying: Downworth would stalk his victims in his van at night before parking and creeping up to throttle them . 'He spoke in hateful and degrading ways whilst attacking them and appeared to be deriving sadistic pleasure from their suffering.' The first victim, 28, who had been drinking with a friend was attacked at 2.50am on December 3 2011 as she crossed bridge over a reservoir at Alexandra Park in Edgeley, near Stockport. She was attacked from behind and grabbed in a headlock before being told: 'Don\\u2019t move or I\\u2019ll stab you - you know what\\u2019s going to happen to you - don\\u2019t you.' He then choked the woman until she lost consciousness before sexually assaulting her as she lay helpless on the floor - then beating her about the face. A second woman, 26, was grabbed the following April as she walked home from a takeaway but he fled with her handbag when she screamed for her partner. This shows Downworth creeping towards his van as he heads off to commit what would be his last crime . Manchester's Minshull Street Crown Court: Today Downworth was given 10 life sentences there . In May 2012, the third victim, 22, was attacked as she walked home at 1am after socialising with friends. She said she was attacked by two men with Downworth ripping off her clothes and telling her:'I\\u2019m not going to hury you. If you s*** me off it will be all over.' A fourth victim, 28, was attacked in the early hours of 1 July 2012 as she walked home through Debdale Park in Gorton after a drinking session with friends. The final known victim, 48, was raped at 1am on September 16 after she left a bar in Stockport. 'So many times I've blamed myself and wondered why it was me.' - one of Downworth's five victims . He attacked her from behind before dragging her by the hair and then ankles down a secluded footpath before raping her twice adding: 'I\\u2019ll have to kill you now.' The woman managed to break free and ran to horrified passersby. Downworth was spotted fleeing the area and police arrested him close to his van. He was linked to the previous attacks by CCTV footage of his van, petrol receipts and tracking of his mobile phones. Two mobile phones stolen from victims were also later found at his home. One victim said later: 'On the night of the attack my life was turned upside down and I have never been the same since. So many times I\\u2019ve blamed myself and wondered why it was me. When I went back to work I kept bursting into tears so I had to give up my job. 'Some of my hair even began to fall out with all the stress. It got to the point where I tried to kill myself.' 'You are to be regarded as dangerous and...there is a serious risk of harm to members of the public.' - Judge Jeffrey Lewis . Downworth claimed he was a street mugger who had not sexually assaulted any victims, and invented a fictitious accomplice who he blamed for the more serious sexual attacks. But Judge Jeffrey Lewis told him: 'You are to be regarded as dangerous and it is as clear to me as it possibly could be that there is a serious risk of harm to members of the public. 'Even your own counsel conceded that these women were attacked and degraded in a horrible way.' After the case Detective Inspector Rebecca Matthews said: 'Downworth subject these women to some of the most appalling attacks I have seen in my policing career. 'The library of books at his home gave a chilling insight into his personality and thought processes, ranging from research on law surrounding sexual offences to hiding your true personality from others. 'Due to the serious nature of his offending, it is possible there may be other victims that have not come forward to police for whatever reason. If this is the case, I would urge them to do so.' She added: 'When we arrested Downworth, we found a library of books at his home that gave a chilling insight into his personality and thought processes, ranging from research on law surrounding sexual offences to hiding your true personality from others.'\",\n          \"(CNN) -- When they're not hunting bad guys, the U.S. Federal Bureau of Investigation has designed a smartphone application for concerned parents. Child ID, the first mobile app made by the FBI, provides parents with a place to keep information about their children handy in case of an emergency. Parents can create separate entries for each kid, complete with photos, height, weight and other descriptive details. Then if a child disappears at the shopping mall, for example, a parent can quickly reference the info from her phone when filing a report to police. The app also has buttons for calling 911 or the national missing children hotline, as well as for transmitting the data about a lost child over the Internet. For anyone skittish about creating dossiers of their family within software conceived by the feds, the FBI lists an \\\"important note\\\" stating: \\\"the FBI (and iTunes for that matter) is not collecting or storing any photos or information that you enter in the app.\\\" The data is kept in the device's memory and only transmitted when using the app for sending a report, the FBI says. Child ID debuted Friday as a free download for Apple iPhone and iPod Touch owners. The FBI plans to release versions of the program for other phones later, the government agency said in a statement. While the FBI is a newbie when it comes to building mobile apps, several other U.S. federal agencies have already released applications. The Internal Revenue Service, the Office of Personnel Management, the State Department, the Transportation Security Administration and the White House all have apps. Many are listed on USA.gov. The U.S. government seems to favor Apple's mobile platform for many of its software releases. Aneesh Chopra, the White House's technology chief, told the blog Switched two years ago that he uses a BlackBerry for work and an iPhone as his personal device.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 39895,\n        \"samples\": [\n          \"Arsenal beat Partizan Belgrade 3-1 to advance to the knockout stages of Champions League .\\nShakhtar Donetsk claim top spot in Group H after 2-0 win over Braga .\\nBenzema scores hat-trick for Real Madrid as they demolish Auxerre 4-0 .\\nChelsea slump in form continues as they lose 1-0 to Marseille but still top Group F .\",\n          \"Group's survey factors in economic growth, democracy, social tolerance .\\nTop 10 include seven European nations, Colombia, Puerto Rico, Canada .\\nU.S. ranked No. 16; Zimbabwe, Moldova, Armenia ranked at bottom .\",\n          \"Mother-of-four Dorothy Clark, 47,died from heart and renal failure .\\nFamily wanted to give the ultimate tribute to the motorbike lover - a 18-ft long trike hearse .\\nThe unique hearse lead a procession of more than 50 motorbikes and trikes .\\nSeveral funeral companies around the UK now have trike hearses to accommodate motorbike enthusiasts .\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 40000,\n        \"samples\": [\n          \"9b711077ba15856ae3c03f31a214be7ce17f1909\",\n          \"97e9295bfe175d08c3a58d49108434353a43d0af\",\n          \"9ece05e2dfad881c27c2b9d9c926a28ddf3d2c47\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"text_tokenizado\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"summary_tokenizado\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "import numpy as np\n",
        "\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "df['text_tokenizado'] = df['article'].apply(lambda x: ['<start>'] + word_tokenize(x.lower()) + ['<end>'])\n",
        "df['summary_tokenizado'] = df['summary'].apply(lambda x: ['<start>'] + word_tokenize(x.lower()) + ['<end>'])\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_tokens = []\n",
        "for tokens in df['text_tokenizado']:\n",
        "  all_tokens.extend(tokens)\n",
        "\n",
        "print(f'Quantidade de tokens: {len(all_tokens)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lfQY7dhRAP6",
        "outputId": "11e79051-4e16-46c2-cac8-43dc65cfa393"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidade de tokens: 31579842\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "counter = Counter(all_tokens)\n",
        "print(counter.most_common(10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hb3dYeohUVSr",
        "outputId": "3b34549c-9c5f-4430-c9d8-5a8df1940e47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('the', 1567054), ('.', 1482894), (',', 1276374), ('to', 751587), ('a', 673486), ('and', 644329), ('of', 635139), ('in', 570873), ('was', 268968), ('that', 261692)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulario = [token for token, i in counter.items() if i >= 2]\n",
        "vocabulario = ['<unk>'] + vocabulario\n",
        "print(f'Quantidade de tokens no vocabulario: {len(vocabulario)}')\n",
        "print(vocabulario[:10])\n",
        "tamanho_vocabulario = len(vocabulario)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hYFZLrwGUcZu",
        "outputId": "aafc1b1e-fb97-4317-f07d-0a4e6adaf268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Quantidade de tokens no vocabulario: 155884\n",
            "['<unk>', '<start>', 'former', 'manchester', 'united', 'striker', 'michael', 'owen', 'has', 'warned']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vetorizando os dados"
      ],
      "metadata": {
        "id": "EMysPMWBdmFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dict_token2id = {token: i for i, token in enumerate(vocabulario)}\n",
        "def token2id(tokens):\n",
        "  return [dict_token2id.get(token, 0) for token in tokens]\n",
        "\n",
        "# Dicionário reverso para converter IDs em palavras\n",
        "id2token = {i: token for token, i in dict_token2id.items()}\n",
        "\n",
        "df['text_token_id'] = df['text_tokenizado'].apply(token2id)\n",
        "df['summary_token_id'] = df['summary_tokenizado'].apply(token2id)\n",
        "\n",
        "\n",
        "# Funçao para padronizar o tamanho dos textos e dos resumos, garantindo que o token '<end>' esteja no final\n",
        "def ajustar_sequencia(seq, limite):\n",
        "    end_token = dict_token2id['<end>']\n",
        "\n",
        "    if len(seq) <= limite:\n",
        "        return seq  # não precisa cortar\n",
        "    if end_token in seq[:limite]: # se o end já está na sequencia cortada\n",
        "      return seq[:limite]\n",
        "    else:\n",
        "      return seq[:limite-1] + [end_token]\n",
        "\n",
        "df['text_token_id'] = df['text_token_id'].apply(lambda x: ajustar_sequencia(x, 500))\n",
        "df['summary_token_id'] = df['summary_token_id'].apply(lambda x: ajustar_sequencia(x, 60))"
      ],
      "metadata": {
        "id": "GHmB-AH6UgvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import model_selection\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "JNXgqTjlUtcs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Criando as entradas do encoder e decoder. Separando os dados em treinamento e validacao"
      ],
      "metadata": {
        "id": "y5TDIrDYdo65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Entrada do decoder: resumo sem o token <end>\n",
        "df['decoder_input'] = df['summary_token_id'].apply(lambda x: x[:-1])\n",
        "\n",
        "# Saída do decoder: resumo sem o token <start>\n",
        "df['decoder_output'] = df['summary_token_id'].apply(lambda x: x[1:])\n",
        "\n",
        "max_len_text = max(df['text_token_id'].apply(len))\n",
        "max_len_summary = max(df['summary_token_id'].apply(len))  # serve para input e output\n",
        "\n",
        "\n",
        "\"\"\"Apesar das sequências originais de texto e resumo terem sido previamente ajustadas para um comprimento fixo, a criação das entradas e\n",
        "saídas do decoder (que removem os tokens <start> e <end>, respectivamente) faz com que essas novas sequências tenham tamanhos variados.\n",
        "Para garantir que não há problemas, aplicou-se o zero padding\"\"\"\n",
        "\n",
        "# Padding\n",
        "X_encoder = pad_sequences(df['text_token_id'], maxlen=max_len_text, padding='post')\n",
        "y_decoder_input = pad_sequences(df['decoder_input'], maxlen=max_len_summary-1, padding='post')\n",
        "y_decoder_output = pad_sequences(df['decoder_output'], maxlen=max_len_summary-1, padding='post')\n",
        "\n",
        "vocab_size_target = tamanho_vocabulario + 1 # para o caractere do padding\n",
        "\n",
        "X_enc_train, X_enc_val, y_dec_in_train, y_dec_in_val, y_dec_out_train, y_dec_out_val = model_selection.train_test_split(\n",
        "    X_encoder, y_decoder_input, y_decoder_output, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "ST52Fk1DcLgz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-nlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rl0IqzyQIRxt",
        "outputId": "60970d44-695a-405f-9635-9f7ea89e400b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras-nlp in /usr/local/lib/python3.11/dist-packages (0.18.1)\n",
            "Requirement already satisfied: keras-hub==0.18.1 in /usr/local/lib/python3.11/dist-packages (from keras-nlp) (0.18.1)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.18.1->keras-nlp) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.18.1->keras-nlp) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.18.1->keras-nlp) (24.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.18.1->keras-nlp) (2024.11.6)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.18.1->keras-nlp) (13.9.4)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.18.1->keras-nlp) (0.3.11)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.11/dist-packages (from keras-hub==0.18.1->keras-nlp) (2.18.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras-hub==0.18.1->keras-nlp) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras-hub==0.18.1->keras-nlp) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from kagglehub->keras-hub==0.18.1->keras-nlp) (4.67.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras-hub==0.18.1->keras-nlp) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras-hub==0.18.1->keras-nlp) (2.18.0)\n",
            "Requirement already satisfied: tensorflow<2.19,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-text->keras-hub==0.18.1->keras-nlp) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras-hub==0.18.1->keras-nlp) (0.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.4.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (5.29.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (4.13.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (1.71.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.8.0)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.37.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras-hub==0.18.1->keras-nlp) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras-hub==0.18.1->keras-nlp) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras-hub==0.18.1->keras-nlp) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->kagglehub->keras-hub==0.18.1->keras-nlp) (2025.1.31)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.45.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.15.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow<2.19,>=2.18.0->tensorflow-text->keras-hub==0.18.1->keras-nlp) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Arquitetura do Modelo"
      ],
      "metadata": {
        "id": "eh1b3KTEdy33"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_nlp\n",
        "from tensorflow.keras.layers import Input, Embedding, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# Hiperparâmetros\n",
        "embedding_dim = 128\n",
        "num_heads = 4\n",
        "ff_dim = 512\n",
        "num_layers = 2\n",
        "\n",
        "# Input e vocabulário\n",
        "encoder_inputs = Input(shape=(None,), dtype='int32', name='encoder_inputs')\n",
        "decoder_inputs = Input(shape=(None,), dtype='int32', name='decoder_inputs')\n",
        "\n",
        "# Embedding compartilhado\n",
        "embedding_layer = Embedding(input_dim=tamanho_vocabulario, output_dim=embedding_dim, mask_zero=True)\n",
        "\n",
        "# Aplica embedding\n",
        "x_enc = embedding_layer(encoder_inputs)\n",
        "x_dec = embedding_layer(decoder_inputs)\n",
        "\n",
        "# Transformer Encoder\n",
        "for i in range(num_layers):\n",
        "    x_enc = keras_nlp.layers.TransformerEncoder(\n",
        "        intermediate_dim=ff_dim,\n",
        "        num_heads=num_heads,\n",
        "        dropout=0.1,\n",
        "        activation=\"relu\",\n",
        "        name=f\"encoder_layer_{i}\"\n",
        "    )(x_enc)\n",
        "\n",
        "# Transformer Decoder\n",
        "for i in range(num_layers):\n",
        "    x_dec = keras_nlp.layers.TransformerDecoder(\n",
        "        intermediate_dim=ff_dim,\n",
        "        num_heads=num_heads,\n",
        "        dropout=0.1,\n",
        "        activation=\"relu\",\n",
        "        name=f\"decoder_layer_{i}\"\n",
        "    )(decoder_sequence=x_dec, encoder_sequence=x_enc)\n",
        "\n",
        "# Saída final\n",
        "output = Dense(tamanho_vocabulario, activation=\"softmax\")(x_dec)\n",
        "\n",
        "#Model Checkpoint\n",
        "mc = ModelCheckpoint('best_model_NLTK_v2.keras', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "es = EarlyStopping(monitor='val_accuracy', mode='max', verbose=1, patience=5)\n",
        "\n",
        "# Modelo final\n",
        "model = Model([encoder_inputs, decoder_inputs], output)\n",
        "model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "1Vk9V9kKZSlN",
        "outputId": "0e79d290-558c-49b6-91f0-f9077e91fbf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)      │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │ \u001b[38;5;34m19,953,152\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_layer_0     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m198,272\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_layer_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m198,272\u001b[0m │ encoder_layer_0[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerEncode…\u001b[0m │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_layer_0     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m264,576\u001b[0m │ embedding[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34m0\u001b[0m],  │\n",
              "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ encoder_layer_1[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_layer_1     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m) │    \u001b[38;5;34m264,576\u001b[0m │ decoder_layer_0[\u001b[38;5;34m…\u001b[0m │\n",
              "│ (\u001b[38;5;33mTransformerDecode…\u001b[0m │                   │            │ encoder_layer_1[\u001b[38;5;34m…\u001b[0m │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m,      │ \u001b[38;5;34m20,109,036\u001b[0m │ decoder_layer_1[\u001b[38;5;34m…\u001b[0m │\n",
              "│                     │ \u001b[38;5;34m155884\u001b[0m)           │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)      │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ embedding           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │ <span style=\"color: #00af00; text-decoration-color: #00af00\">19,953,152</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_layer_0     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ encoder_layer_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">198,272</span> │ encoder_layer_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerEncode…</span> │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_layer_0     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">264,576</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],  │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ encoder_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ decoder_layer_1     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>) │    <span style=\"color: #00af00; text-decoration-color: #00af00\">264,576</span> │ decoder_layer_0[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TransformerDecode…</span> │                   │            │ encoder_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>,      │ <span style=\"color: #00af00; text-decoration-color: #00af00\">20,109,036</span> │ decoder_layer_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
              "│                     │ <span style=\"color: #00af00; text-decoration-color: #00af00\">155884</span>)           │            │                   │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m40,987,884\u001b[0m (156.36 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,987,884</span> (156.36 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m40,987,884\u001b[0m (156.36 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">40,987,884</span> (156.36 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    [X_encoder, y_decoder_input],   # entradas: texto completo + resumo com <start>\n",
        "    y_decoder_output,               # saída: resumo com <end> (como inteiros, sem one-hot)\n",
        "    batch_size=64,\n",
        "    epochs=250,\n",
        "    validation_data=([X_enc_val, y_dec_in_val], y_dec_out_val),\n",
        "    callbacks=[es, mc]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h5fS954TXbAX",
        "outputId": "7cca7da4-47f0-4ca6-a72c-39c022184b7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:938: UserWarning: Layer 'query' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:938: UserWarning: Layer 'key' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/layer.py:938: UserWarning: Layer 'value' (of type EinsumDense) was passed an input with a mask attached to it. However, this layer does not support masking and will therefore destroy the mask information. Downstream layers will not see the mask.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.0862 - loss: 7.6331\n",
            "Epoch 1: val_accuracy improved from -inf to 0.15587, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m116s\u001b[0m 75ms/step - accuracy: 0.0863 - loss: 7.6318 - val_accuracy: 0.1559 - val_loss: 5.7864\n",
            "Epoch 2/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.1555 - loss: 5.7345\n",
            "Epoch 2: val_accuracy improved from 0.15587 to 0.18432, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.1555 - loss: 5.7344 - val_accuracy: 0.1843 - val_loss: 5.1119\n",
            "Epoch 3/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.1810 - loss: 5.1352\n",
            "Epoch 3: val_accuracy improved from 0.18432 to 0.20409, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 62ms/step - accuracy: 0.1810 - loss: 5.1352 - val_accuracy: 0.2041 - val_loss: 4.6566\n",
            "Epoch 4/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.2007 - loss: 4.7079\n",
            "Epoch 4: val_accuracy improved from 0.20409 to 0.22361, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.2007 - loss: 4.7080 - val_accuracy: 0.2236 - val_loss: 4.3113\n",
            "Epoch 5/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.2156 - loss: 4.3819\n",
            "Epoch 5: val_accuracy improved from 0.22361 to 0.24201, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.2156 - loss: 4.3820 - val_accuracy: 0.2420 - val_loss: 4.0433\n",
            "Epoch 6/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.2319 - loss: 4.1205\n",
            "Epoch 6: val_accuracy improved from 0.24201 to 0.26431, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.2319 - loss: 4.1206 - val_accuracy: 0.2643 - val_loss: 3.7757\n",
            "Epoch 7/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.2476 - loss: 3.8929\n",
            "Epoch 7: val_accuracy improved from 0.26431 to 0.28671, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 62ms/step - accuracy: 0.2476 - loss: 3.8931 - val_accuracy: 0.2867 - val_loss: 3.5399\n",
            "Epoch 8/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.2655 - loss: 3.6926\n",
            "Epoch 8: val_accuracy improved from 0.28671 to 0.30254, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 62ms/step - accuracy: 0.2654 - loss: 3.6928 - val_accuracy: 0.3025 - val_loss: 3.3091\n",
            "Epoch 9/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.2817 - loss: 3.4996\n",
            "Epoch 9: val_accuracy improved from 0.30254 to 0.32761, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.2817 - loss: 3.4998 - val_accuracy: 0.3276 - val_loss: 3.0808\n",
            "Epoch 10/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.2979 - loss: 3.3370\n",
            "Epoch 10: val_accuracy improved from 0.32761 to 0.34741, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.2979 - loss: 3.3371 - val_accuracy: 0.3474 - val_loss: 2.9058\n",
            "Epoch 11/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.3154 - loss: 3.1830\n",
            "Epoch 11: val_accuracy improved from 0.34741 to 0.36749, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.3154 - loss: 3.1831 - val_accuracy: 0.3675 - val_loss: 2.7484\n",
            "Epoch 12/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.3259 - loss: 3.0542\n",
            "Epoch 12: val_accuracy improved from 0.36749 to 0.38735, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.3259 - loss: 3.0543 - val_accuracy: 0.3873 - val_loss: 2.6037\n",
            "Epoch 13/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.3403 - loss: 2.9325\n",
            "Epoch 13: val_accuracy improved from 0.38735 to 0.40218, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.3403 - loss: 2.9327 - val_accuracy: 0.4022 - val_loss: 2.4816\n",
            "Epoch 14/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.3511 - loss: 2.8207\n",
            "Epoch 14: val_accuracy improved from 0.40218 to 0.41605, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.3511 - loss: 2.8208 - val_accuracy: 0.4161 - val_loss: 2.3694\n",
            "Epoch 15/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.3640 - loss: 2.7183\n",
            "Epoch 15: val_accuracy improved from 0.41605 to 0.43582, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.3640 - loss: 2.7185 - val_accuracy: 0.4358 - val_loss: 2.2542\n",
            "Epoch 16/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.3765 - loss: 2.6225\n",
            "Epoch 16: val_accuracy improved from 0.43582 to 0.44758, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.3765 - loss: 2.6227 - val_accuracy: 0.4476 - val_loss: 2.1513\n",
            "Epoch 17/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.3863 - loss: 2.5351\n",
            "Epoch 17: val_accuracy improved from 0.44758 to 0.46249, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.3863 - loss: 2.5353 - val_accuracy: 0.4625 - val_loss: 2.0653\n",
            "Epoch 18/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.3983 - loss: 2.4563\n",
            "Epoch 18: val_accuracy improved from 0.46249 to 0.47510, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.3983 - loss: 2.4565 - val_accuracy: 0.4751 - val_loss: 1.9727\n",
            "Epoch 19/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4063 - loss: 2.3807\n",
            "Epoch 19: val_accuracy improved from 0.47510 to 0.48646, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.4063 - loss: 2.3809 - val_accuracy: 0.4865 - val_loss: 1.9049\n",
            "Epoch 20/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4158 - loss: 2.2978\n",
            "Epoch 20: val_accuracy improved from 0.48646 to 0.49917, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.4158 - loss: 2.2979 - val_accuracy: 0.4992 - val_loss: 1.8189\n",
            "Epoch 21/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4244 - loss: 2.2342\n",
            "Epoch 21: val_accuracy improved from 0.49917 to 0.50729, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 62ms/step - accuracy: 0.4244 - loss: 2.2343 - val_accuracy: 0.5073 - val_loss: 1.7539\n",
            "Epoch 22/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4330 - loss: 2.1710\n",
            "Epoch 22: val_accuracy improved from 0.50729 to 0.52261, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.4330 - loss: 2.1711 - val_accuracy: 0.5226 - val_loss: 1.6808\n",
            "Epoch 23/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4408 - loss: 2.1066\n",
            "Epoch 23: val_accuracy improved from 0.52261 to 0.52810, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.4408 - loss: 2.1067 - val_accuracy: 0.5281 - val_loss: 1.6238\n",
            "Epoch 24/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4484 - loss: 2.0554\n",
            "Epoch 24: val_accuracy improved from 0.52810 to 0.53556, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.4484 - loss: 2.0556 - val_accuracy: 0.5356 - val_loss: 1.5769\n",
            "Epoch 25/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4550 - loss: 2.0064\n",
            "Epoch 25: val_accuracy improved from 0.53556 to 0.54588, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 62ms/step - accuracy: 0.4550 - loss: 2.0066 - val_accuracy: 0.5459 - val_loss: 1.5189\n",
            "Epoch 26/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4629 - loss: 1.9556\n",
            "Epoch 26: val_accuracy improved from 0.54588 to 0.55629, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.4628 - loss: 1.9558 - val_accuracy: 0.5563 - val_loss: 1.4596\n",
            "Epoch 27/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4691 - loss: 1.9100\n",
            "Epoch 27: val_accuracy improved from 0.55629 to 0.56460, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 62ms/step - accuracy: 0.4691 - loss: 1.9101 - val_accuracy: 0.5646 - val_loss: 1.4142\n",
            "Epoch 28/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4754 - loss: 1.8630\n",
            "Epoch 28: val_accuracy improved from 0.56460 to 0.57061, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.4754 - loss: 1.8631 - val_accuracy: 0.5706 - val_loss: 1.3739\n",
            "Epoch 29/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4803 - loss: 1.8290\n",
            "Epoch 29: val_accuracy improved from 0.57061 to 0.57597, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.4803 - loss: 1.8291 - val_accuracy: 0.5760 - val_loss: 1.3334\n",
            "Epoch 30/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4863 - loss: 1.7829\n",
            "Epoch 30: val_accuracy improved from 0.57597 to 0.58817, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.4863 - loss: 1.7831 - val_accuracy: 0.5882 - val_loss: 1.2813\n",
            "Epoch 31/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.4932 - loss: 1.7423\n",
            "Epoch 31: val_accuracy improved from 0.58817 to 0.59256, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 62ms/step - accuracy: 0.4932 - loss: 1.7424 - val_accuracy: 0.5926 - val_loss: 1.2472\n",
            "Epoch 32/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.4988 - loss: 1.7014\n",
            "Epoch 32: val_accuracy improved from 0.59256 to 0.59944, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.4988 - loss: 1.7015 - val_accuracy: 0.5994 - val_loss: 1.2100\n",
            "Epoch 33/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5053 - loss: 1.6631\n",
            "Epoch 33: val_accuracy improved from 0.59944 to 0.60626, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.5053 - loss: 1.6633 - val_accuracy: 0.6063 - val_loss: 1.1647\n",
            "Epoch 34/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5077 - loss: 1.6388\n",
            "Epoch 34: val_accuracy improved from 0.60626 to 0.61354, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.5077 - loss: 1.6389 - val_accuracy: 0.6135 - val_loss: 1.1269\n",
            "Epoch 35/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5147 - loss: 1.5972\n",
            "Epoch 35: val_accuracy improved from 0.61354 to 0.62186, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.5147 - loss: 1.5973 - val_accuracy: 0.6219 - val_loss: 1.0914\n",
            "Epoch 36/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5197 - loss: 1.5652\n",
            "Epoch 36: val_accuracy improved from 0.62186 to 0.62281, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.5197 - loss: 1.5653 - val_accuracy: 0.6228 - val_loss: 1.0643\n",
            "Epoch 37/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5245 - loss: 1.5314\n",
            "Epoch 37: val_accuracy improved from 0.62281 to 0.63116, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.5245 - loss: 1.5315 - val_accuracy: 0.6312 - val_loss: 1.0294\n",
            "Epoch 38/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5301 - loss: 1.5005\n",
            "Epoch 38: val_accuracy improved from 0.63116 to 0.64211, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.5301 - loss: 1.5006 - val_accuracy: 0.6421 - val_loss: 0.9938\n",
            "Epoch 39/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5356 - loss: 1.4732\n",
            "Epoch 39: val_accuracy improved from 0.64211 to 0.64267, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 62ms/step - accuracy: 0.5356 - loss: 1.4733 - val_accuracy: 0.6427 - val_loss: 0.9670\n",
            "Epoch 40/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5404 - loss: 1.4429\n",
            "Epoch 40: val_accuracy improved from 0.64267 to 0.64806, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 62ms/step - accuracy: 0.5404 - loss: 1.4430 - val_accuracy: 0.6481 - val_loss: 0.9378\n",
            "Epoch 41/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5437 - loss: 1.4176\n",
            "Epoch 41: val_accuracy improved from 0.64806 to 0.65582, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.5437 - loss: 1.4177 - val_accuracy: 0.6558 - val_loss: 0.9032\n",
            "Epoch 42/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5492 - loss: 1.3866\n",
            "Epoch 42: val_accuracy improved from 0.65582 to 0.65772, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.5492 - loss: 1.3867 - val_accuracy: 0.6577 - val_loss: 0.8792\n",
            "Epoch 43/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5522 - loss: 1.3657\n",
            "Epoch 43: val_accuracy improved from 0.65772 to 0.66028, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.5521 - loss: 1.3658 - val_accuracy: 0.6603 - val_loss: 0.8578\n",
            "Epoch 44/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5563 - loss: 1.3344\n",
            "Epoch 44: val_accuracy improved from 0.66028 to 0.66800, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.5563 - loss: 1.3345 - val_accuracy: 0.6680 - val_loss: 0.8305\n",
            "Epoch 45/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5610 - loss: 1.3073\n",
            "Epoch 45: val_accuracy improved from 0.66800 to 0.67306, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 62ms/step - accuracy: 0.5610 - loss: 1.3074 - val_accuracy: 0.6731 - val_loss: 0.7984\n",
            "Epoch 46/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5645 - loss: 1.2874\n",
            "Epoch 46: val_accuracy improved from 0.67306 to 0.67898, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.5645 - loss: 1.2875 - val_accuracy: 0.6790 - val_loss: 0.7812\n",
            "Epoch 47/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5689 - loss: 1.2652\n",
            "Epoch 47: val_accuracy improved from 0.67898 to 0.68018, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 62ms/step - accuracy: 0.5689 - loss: 1.2653 - val_accuracy: 0.6802 - val_loss: 0.7595\n",
            "Epoch 48/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5726 - loss: 1.2408\n",
            "Epoch 48: val_accuracy improved from 0.68018 to 0.68479, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.5726 - loss: 1.2409 - val_accuracy: 0.6848 - val_loss: 0.7350\n",
            "Epoch 49/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5763 - loss: 1.2070\n",
            "Epoch 49: val_accuracy improved from 0.68479 to 0.68713, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.5762 - loss: 1.2071 - val_accuracy: 0.6871 - val_loss: 0.7139\n",
            "Epoch 50/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5792 - loss: 1.1984\n",
            "Epoch 50: val_accuracy improved from 0.68713 to 0.69253, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 63ms/step - accuracy: 0.5792 - loss: 1.1985 - val_accuracy: 0.6925 - val_loss: 0.6845\n",
            "Epoch 51/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5835 - loss: 1.1718\n",
            "Epoch 51: val_accuracy improved from 0.69253 to 0.69725, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.5835 - loss: 1.1719 - val_accuracy: 0.6973 - val_loss: 0.6702\n",
            "Epoch 52/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5880 - loss: 1.1504\n",
            "Epoch 52: val_accuracy improved from 0.69725 to 0.70021, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.5880 - loss: 1.1504 - val_accuracy: 0.7002 - val_loss: 0.6550\n",
            "Epoch 53/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5906 - loss: 1.1297\n",
            "Epoch 53: val_accuracy improved from 0.70021 to 0.70562, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.5905 - loss: 1.1298 - val_accuracy: 0.7056 - val_loss: 0.6316\n",
            "Epoch 54/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5932 - loss: 1.1156\n",
            "Epoch 54: val_accuracy improved from 0.70562 to 0.71095, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.5932 - loss: 1.1157 - val_accuracy: 0.7109 - val_loss: 0.6104\n",
            "Epoch 55/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.5982 - loss: 1.0930\n",
            "Epoch 55: val_accuracy improved from 0.71095 to 0.71375, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.5982 - loss: 1.0931 - val_accuracy: 0.7138 - val_loss: 0.5930\n",
            "Epoch 56/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6007 - loss: 1.0753\n",
            "Epoch 56: val_accuracy improved from 0.71375 to 0.71525, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6007 - loss: 1.0754 - val_accuracy: 0.7153 - val_loss: 0.5778\n",
            "Epoch 57/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6063 - loss: 1.0536\n",
            "Epoch 57: val_accuracy improved from 0.71525 to 0.71875, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6063 - loss: 1.0537 - val_accuracy: 0.7187 - val_loss: 0.5669\n",
            "Epoch 58/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6071 - loss: 1.0385\n",
            "Epoch 58: val_accuracy improved from 0.71875 to 0.72287, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6071 - loss: 1.0385 - val_accuracy: 0.7229 - val_loss: 0.5463\n",
            "Epoch 59/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6128 - loss: 1.0168\n",
            "Epoch 59: val_accuracy improved from 0.72287 to 0.72545, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6127 - loss: 1.0169 - val_accuracy: 0.7255 - val_loss: 0.5258\n",
            "Epoch 60/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6151 - loss: 1.0019\n",
            "Epoch 60: val_accuracy improved from 0.72545 to 0.72789, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6151 - loss: 1.0020 - val_accuracy: 0.7279 - val_loss: 0.5141\n",
            "Epoch 61/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6167 - loss: 0.9903\n",
            "Epoch 61: val_accuracy improved from 0.72789 to 0.73163, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6166 - loss: 0.9903 - val_accuracy: 0.7316 - val_loss: 0.4937\n",
            "Epoch 62/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6226 - loss: 0.9684\n",
            "Epoch 62: val_accuracy improved from 0.73163 to 0.73490, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6225 - loss: 0.9685 - val_accuracy: 0.7349 - val_loss: 0.4929\n",
            "Epoch 63/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6231 - loss: 0.9578\n",
            "Epoch 63: val_accuracy improved from 0.73490 to 0.73857, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6231 - loss: 0.9578 - val_accuracy: 0.7386 - val_loss: 0.4759\n",
            "Epoch 64/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6264 - loss: 0.9435\n",
            "Epoch 64: val_accuracy improved from 0.73857 to 0.73917, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6264 - loss: 0.9436 - val_accuracy: 0.7392 - val_loss: 0.4647\n",
            "Epoch 65/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6288 - loss: 0.9261\n",
            "Epoch 65: val_accuracy improved from 0.73917 to 0.74070, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6288 - loss: 0.9262 - val_accuracy: 0.7407 - val_loss: 0.4525\n",
            "Epoch 66/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6319 - loss: 0.9117\n",
            "Epoch 66: val_accuracy improved from 0.74070 to 0.74434, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6319 - loss: 0.9118 - val_accuracy: 0.7443 - val_loss: 0.4291\n",
            "Epoch 67/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6341 - loss: 0.8963\n",
            "Epoch 67: val_accuracy improved from 0.74434 to 0.74489, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6341 - loss: 0.8963 - val_accuracy: 0.7449 - val_loss: 0.4287\n",
            "Epoch 68/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6347 - loss: 0.8882\n",
            "Epoch 68: val_accuracy improved from 0.74489 to 0.74746, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6347 - loss: 0.8883 - val_accuracy: 0.7475 - val_loss: 0.4189\n",
            "Epoch 69/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6396 - loss: 0.8705\n",
            "Epoch 69: val_accuracy did not improve from 0.74746\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 58ms/step - accuracy: 0.6396 - loss: 0.8705 - val_accuracy: 0.7471 - val_loss: 0.4104\n",
            "Epoch 70/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6413 - loss: 0.8576\n",
            "Epoch 70: val_accuracy improved from 0.74746 to 0.75217, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6412 - loss: 0.8577 - val_accuracy: 0.7522 - val_loss: 0.3892\n",
            "Epoch 71/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6439 - loss: 0.8474\n",
            "Epoch 71: val_accuracy improved from 0.75217 to 0.75424, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6439 - loss: 0.8474 - val_accuracy: 0.7542 - val_loss: 0.3787\n",
            "Epoch 72/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6458 - loss: 0.8363\n",
            "Epoch 72: val_accuracy improved from 0.75424 to 0.75764, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6458 - loss: 0.8364 - val_accuracy: 0.7576 - val_loss: 0.3706\n",
            "Epoch 73/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6490 - loss: 0.8186\n",
            "Epoch 73: val_accuracy did not improve from 0.75764\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 58ms/step - accuracy: 0.6490 - loss: 0.8186 - val_accuracy: 0.7572 - val_loss: 0.3666\n",
            "Epoch 74/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6527 - loss: 0.8057\n",
            "Epoch 74: val_accuracy improved from 0.75764 to 0.75948, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 62ms/step - accuracy: 0.6527 - loss: 0.8057 - val_accuracy: 0.7595 - val_loss: 0.3558\n",
            "Epoch 75/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6544 - loss: 0.7977\n",
            "Epoch 75: val_accuracy improved from 0.75948 to 0.76281, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6544 - loss: 0.7977 - val_accuracy: 0.7628 - val_loss: 0.3441\n",
            "Epoch 76/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6570 - loss: 0.7895\n",
            "Epoch 76: val_accuracy did not improve from 0.76281\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 58ms/step - accuracy: 0.6569 - loss: 0.7896 - val_accuracy: 0.7627 - val_loss: 0.3389\n",
            "Epoch 77/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.6573 - loss: 0.7762\n",
            "Epoch 77: val_accuracy improved from 0.76281 to 0.76468, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 61ms/step - accuracy: 0.6573 - loss: 0.7762 - val_accuracy: 0.7647 - val_loss: 0.3302\n",
            "Epoch 78/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6608 - loss: 0.7662\n",
            "Epoch 78: val_accuracy improved from 0.76468 to 0.76664, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6608 - loss: 0.7663 - val_accuracy: 0.7666 - val_loss: 0.3169\n",
            "Epoch 79/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6628 - loss: 0.7566\n",
            "Epoch 79: val_accuracy improved from 0.76664 to 0.76984, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6628 - loss: 0.7566 - val_accuracy: 0.7698 - val_loss: 0.3091\n",
            "Epoch 80/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6648 - loss: 0.7485\n",
            "Epoch 80: val_accuracy did not improve from 0.76984\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 58ms/step - accuracy: 0.6647 - loss: 0.7485 - val_accuracy: 0.7691 - val_loss: 0.3075\n",
            "Epoch 81/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6662 - loss: 0.7359\n",
            "Epoch 81: val_accuracy improved from 0.76984 to 0.77080, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 62ms/step - accuracy: 0.6662 - loss: 0.7360 - val_accuracy: 0.7708 - val_loss: 0.3003\n",
            "Epoch 82/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6689 - loss: 0.7251\n",
            "Epoch 82: val_accuracy improved from 0.77080 to 0.77150, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6689 - loss: 0.7252 - val_accuracy: 0.7715 - val_loss: 0.2925\n",
            "Epoch 83/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6687 - loss: 0.7220\n",
            "Epoch 83: val_accuracy improved from 0.77150 to 0.77424, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6687 - loss: 0.7220 - val_accuracy: 0.7742 - val_loss: 0.2844\n",
            "Epoch 84/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6732 - loss: 0.7099\n",
            "Epoch 84: val_accuracy improved from 0.77424 to 0.77533, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6732 - loss: 0.7099 - val_accuracy: 0.7753 - val_loss: 0.2777\n",
            "Epoch 85/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6734 - loss: 0.7022\n",
            "Epoch 85: val_accuracy improved from 0.77533 to 0.77586, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6734 - loss: 0.7022 - val_accuracy: 0.7759 - val_loss: 0.2710\n",
            "Epoch 86/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6753 - loss: 0.6941\n",
            "Epoch 86: val_accuracy improved from 0.77586 to 0.77804, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6753 - loss: 0.6941 - val_accuracy: 0.7780 - val_loss: 0.2664\n",
            "Epoch 87/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6775 - loss: 0.6853\n",
            "Epoch 87: val_accuracy improved from 0.77804 to 0.78021, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6774 - loss: 0.6854 - val_accuracy: 0.7802 - val_loss: 0.2585\n",
            "Epoch 88/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6807 - loss: 0.6749\n",
            "Epoch 88: val_accuracy improved from 0.78021 to 0.78106, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6807 - loss: 0.6749 - val_accuracy: 0.7811 - val_loss: 0.2544\n",
            "Epoch 89/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6800 - loss: 0.6705\n",
            "Epoch 89: val_accuracy improved from 0.78106 to 0.78107, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6800 - loss: 0.6706 - val_accuracy: 0.7811 - val_loss: 0.2491\n",
            "Epoch 90/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6815 - loss: 0.6603\n",
            "Epoch 90: val_accuracy improved from 0.78107 to 0.78251, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6815 - loss: 0.6603 - val_accuracy: 0.7825 - val_loss: 0.2430\n",
            "Epoch 91/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6840 - loss: 0.6516\n",
            "Epoch 91: val_accuracy improved from 0.78251 to 0.78428, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6840 - loss: 0.6517 - val_accuracy: 0.7843 - val_loss: 0.2387\n",
            "Epoch 92/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6856 - loss: 0.6460\n",
            "Epoch 92: val_accuracy did not improve from 0.78428\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 58ms/step - accuracy: 0.6856 - loss: 0.6460 - val_accuracy: 0.7837 - val_loss: 0.2371\n",
            "Epoch 93/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6858 - loss: 0.6416\n",
            "Epoch 93: val_accuracy improved from 0.78428 to 0.78547, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6858 - loss: 0.6416 - val_accuracy: 0.7855 - val_loss: 0.2324\n",
            "Epoch 94/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6861 - loss: 0.6331\n",
            "Epoch 94: val_accuracy improved from 0.78547 to 0.78749, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6861 - loss: 0.6332 - val_accuracy: 0.7875 - val_loss: 0.2216\n",
            "Epoch 95/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6901 - loss: 0.6271\n",
            "Epoch 95: val_accuracy did not improve from 0.78749\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 58ms/step - accuracy: 0.6901 - loss: 0.6271 - val_accuracy: 0.7869 - val_loss: 0.2212\n",
            "Epoch 96/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6908 - loss: 0.6184\n",
            "Epoch 96: val_accuracy improved from 0.78749 to 0.78892, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6908 - loss: 0.6184 - val_accuracy: 0.7889 - val_loss: 0.2136\n",
            "Epoch 97/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6934 - loss: 0.6136\n",
            "Epoch 97: val_accuracy improved from 0.78892 to 0.78897, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6934 - loss: 0.6136 - val_accuracy: 0.7890 - val_loss: 0.2176\n",
            "Epoch 98/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6959 - loss: 0.6038\n",
            "Epoch 98: val_accuracy improved from 0.78897 to 0.78984, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6958 - loss: 0.6038 - val_accuracy: 0.7898 - val_loss: 0.2072\n",
            "Epoch 99/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6936 - loss: 0.5971\n",
            "Epoch 99: val_accuracy improved from 0.78984 to 0.79093, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6936 - loss: 0.5972 - val_accuracy: 0.7909 - val_loss: 0.2044\n",
            "Epoch 100/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6945 - loss: 0.5931\n",
            "Epoch 100: val_accuracy improved from 0.79093 to 0.79195, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6945 - loss: 0.5932 - val_accuracy: 0.7919 - val_loss: 0.1998\n",
            "Epoch 101/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6972 - loss: 0.5879\n",
            "Epoch 101: val_accuracy improved from 0.79195 to 0.79356, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.6972 - loss: 0.5879 - val_accuracy: 0.7936 - val_loss: 0.1940\n",
            "Epoch 102/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7002 - loss: 0.5805\n",
            "Epoch 102: val_accuracy did not improve from 0.79356\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 58ms/step - accuracy: 0.7002 - loss: 0.5806 - val_accuracy: 0.7927 - val_loss: 0.1948\n",
            "Epoch 103/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6992 - loss: 0.5762\n",
            "Epoch 103: val_accuracy did not improve from 0.79356\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 58ms/step - accuracy: 0.6992 - loss: 0.5763 - val_accuracy: 0.7934 - val_loss: 0.1940\n",
            "Epoch 104/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7006 - loss: 0.5691\n",
            "Epoch 104: val_accuracy improved from 0.79356 to 0.79469, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.7006 - loss: 0.5691 - val_accuracy: 0.7947 - val_loss: 0.1853\n",
            "Epoch 105/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7031 - loss: 0.5626\n",
            "Epoch 105: val_accuracy did not improve from 0.79469\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 59ms/step - accuracy: 0.7031 - loss: 0.5626 - val_accuracy: 0.7938 - val_loss: 0.1873\n",
            "Epoch 106/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7034 - loss: 0.5573\n",
            "Epoch 106: val_accuracy improved from 0.79469 to 0.79540, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.7034 - loss: 0.5574 - val_accuracy: 0.7954 - val_loss: 0.1807\n",
            "Epoch 107/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7048 - loss: 0.5559\n",
            "Epoch 107: val_accuracy improved from 0.79540 to 0.79650, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.7048 - loss: 0.5559 - val_accuracy: 0.7965 - val_loss: 0.1763\n",
            "Epoch 108/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7071 - loss: 0.5506\n",
            "Epoch 108: val_accuracy improved from 0.79650 to 0.79711, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.7071 - loss: 0.5507 - val_accuracy: 0.7971 - val_loss: 0.1734\n",
            "Epoch 109/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7058 - loss: 0.5468\n",
            "Epoch 109: val_accuracy did not improve from 0.79711\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 58ms/step - accuracy: 0.7058 - loss: 0.5468 - val_accuracy: 0.7968 - val_loss: 0.1728\n",
            "Epoch 110/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7080 - loss: 0.5394\n",
            "Epoch 110: val_accuracy improved from 0.79711 to 0.79769, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.7080 - loss: 0.5394 - val_accuracy: 0.7977 - val_loss: 0.1693\n",
            "Epoch 111/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7102 - loss: 0.5342\n",
            "Epoch 111: val_accuracy did not improve from 0.79769\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 58ms/step - accuracy: 0.7102 - loss: 0.5342 - val_accuracy: 0.7974 - val_loss: 0.1708\n",
            "Epoch 112/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7103 - loss: 0.5303\n",
            "Epoch 112: val_accuracy improved from 0.79769 to 0.79932, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.7103 - loss: 0.5303 - val_accuracy: 0.7993 - val_loss: 0.1638\n",
            "Epoch 113/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7119 - loss: 0.5257\n",
            "Epoch 113: val_accuracy improved from 0.79932 to 0.80098, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.7119 - loss: 0.5257 - val_accuracy: 0.8010 - val_loss: 0.1579\n",
            "Epoch 114/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7119 - loss: 0.5203\n",
            "Epoch 114: val_accuracy did not improve from 0.80098\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 58ms/step - accuracy: 0.7119 - loss: 0.5203 - val_accuracy: 0.8004 - val_loss: 0.1568\n",
            "Epoch 115/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7129 - loss: 0.5129\n",
            "Epoch 115: val_accuracy improved from 0.80098 to 0.80149, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.7129 - loss: 0.5130 - val_accuracy: 0.8015 - val_loss: 0.1559\n",
            "Epoch 116/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7139 - loss: 0.5125\n",
            "Epoch 116: val_accuracy improved from 0.80149 to 0.80180, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.7139 - loss: 0.5125 - val_accuracy: 0.8018 - val_loss: 0.1545\n",
            "Epoch 117/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7154 - loss: 0.5108\n",
            "Epoch 117: val_accuracy did not improve from 0.80180\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 59ms/step - accuracy: 0.7154 - loss: 0.5109 - val_accuracy: 0.8014 - val_loss: 0.1528\n",
            "Epoch 118/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7152 - loss: 0.5062\n",
            "Epoch 118: val_accuracy did not improve from 0.80180\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 58ms/step - accuracy: 0.7152 - loss: 0.5062 - val_accuracy: 0.8014 - val_loss: 0.1527\n",
            "Epoch 119/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7160 - loss: 0.4995\n",
            "Epoch 119: val_accuracy improved from 0.80180 to 0.80268, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.7160 - loss: 0.4995 - val_accuracy: 0.8027 - val_loss: 0.1492\n",
            "Epoch 120/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7192 - loss: 0.4958\n",
            "Epoch 120: val_accuracy improved from 0.80268 to 0.80293, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.7192 - loss: 0.4958 - val_accuracy: 0.8029 - val_loss: 0.1450\n",
            "Epoch 121/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7197 - loss: 0.4901\n",
            "Epoch 121: val_accuracy did not improve from 0.80293\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 58ms/step - accuracy: 0.7197 - loss: 0.4902 - val_accuracy: 0.8018 - val_loss: 0.1497\n",
            "Epoch 122/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7178 - loss: 0.4885\n",
            "Epoch 122: val_accuracy improved from 0.80293 to 0.80421, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.7178 - loss: 0.4885 - val_accuracy: 0.8042 - val_loss: 0.1400\n",
            "Epoch 123/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7204 - loss: 0.4865\n",
            "Epoch 123: val_accuracy did not improve from 0.80421\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 58ms/step - accuracy: 0.7204 - loss: 0.4866 - val_accuracy: 0.8038 - val_loss: 0.1391\n",
            "Epoch 124/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7220 - loss: 0.4810\n",
            "Epoch 124: val_accuracy improved from 0.80421 to 0.80470, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.7220 - loss: 0.4810 - val_accuracy: 0.8047 - val_loss: 0.1377\n",
            "Epoch 125/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7232 - loss: 0.4756\n",
            "Epoch 125: val_accuracy improved from 0.80470 to 0.80521, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.7232 - loss: 0.4756 - val_accuracy: 0.8052 - val_loss: 0.1356\n",
            "Epoch 126/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7225 - loss: 0.4710\n",
            "Epoch 126: val_accuracy improved from 0.80521 to 0.80556, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.7225 - loss: 0.4711 - val_accuracy: 0.8056 - val_loss: 0.1338\n",
            "Epoch 127/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7229 - loss: 0.4682\n",
            "Epoch 127: val_accuracy did not improve from 0.80556\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 59ms/step - accuracy: 0.7229 - loss: 0.4682 - val_accuracy: 0.8043 - val_loss: 0.1345\n",
            "Epoch 128/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7243 - loss: 0.4655\n",
            "Epoch 128: val_accuracy did not improve from 0.80556\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 58ms/step - accuracy: 0.7243 - loss: 0.4655 - val_accuracy: 0.8052 - val_loss: 0.1347\n",
            "Epoch 129/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7252 - loss: 0.4640\n",
            "Epoch 129: val_accuracy improved from 0.80556 to 0.80638, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.7252 - loss: 0.4640 - val_accuracy: 0.8064 - val_loss: 0.1278\n",
            "Epoch 130/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7256 - loss: 0.4577\n",
            "Epoch 130: val_accuracy did not improve from 0.80638\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 59ms/step - accuracy: 0.7256 - loss: 0.4577 - val_accuracy: 0.8063 - val_loss: 0.1305\n",
            "Epoch 131/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7272 - loss: 0.4541\n",
            "Epoch 131: val_accuracy improved from 0.80638 to 0.80665, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.7272 - loss: 0.4542 - val_accuracy: 0.8066 - val_loss: 0.1274\n",
            "Epoch 132/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7269 - loss: 0.4534\n",
            "Epoch 132: val_accuracy did not improve from 0.80665\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 59ms/step - accuracy: 0.7269 - loss: 0.4534 - val_accuracy: 0.8065 - val_loss: 0.1249\n",
            "Epoch 133/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7270 - loss: 0.4501\n",
            "Epoch 133: val_accuracy improved from 0.80665 to 0.80759, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.7270 - loss: 0.4501 - val_accuracy: 0.8076 - val_loss: 0.1234\n",
            "Epoch 134/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7306 - loss: 0.4446\n",
            "Epoch 134: val_accuracy did not improve from 0.80759\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 59ms/step - accuracy: 0.7306 - loss: 0.4447 - val_accuracy: 0.8070 - val_loss: 0.1224\n",
            "Epoch 135/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7304 - loss: 0.4430\n",
            "Epoch 135: val_accuracy improved from 0.80759 to 0.80829, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.7304 - loss: 0.4431 - val_accuracy: 0.8083 - val_loss: 0.1194\n",
            "Epoch 136/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7297 - loss: 0.4410\n",
            "Epoch 136: val_accuracy improved from 0.80829 to 0.80952, saving model to /content/drive/MyDrive/Projeto Final Deep Learning/best_model_NLTK.keras\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 62ms/step - accuracy: 0.7297 - loss: 0.4410 - val_accuracy: 0.8095 - val_loss: 0.1185\n",
            "Epoch 137/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7317 - loss: 0.4365\n",
            "Epoch 137: val_accuracy did not improve from 0.80952\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 58ms/step - accuracy: 0.7317 - loss: 0.4365 - val_accuracy: 0.8091 - val_loss: 0.1139\n",
            "Epoch 138/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7305 - loss: 0.4329\n",
            "Epoch 138: val_accuracy did not improve from 0.80952\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 58ms/step - accuracy: 0.7305 - loss: 0.4329 - val_accuracy: 0.8090 - val_loss: 0.1163\n",
            "Epoch 139/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7330 - loss: 0.4290\n",
            "Epoch 139: val_accuracy did not improve from 0.80952\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 58ms/step - accuracy: 0.7330 - loss: 0.4291 - val_accuracy: 0.8088 - val_loss: 0.1168\n",
            "Epoch 140/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7321 - loss: 0.4313\n",
            "Epoch 140: val_accuracy did not improve from 0.80952\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 58ms/step - accuracy: 0.7321 - loss: 0.4313 - val_accuracy: 0.8095 - val_loss: 0.1117\n",
            "Epoch 141/250\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7340 - loss: 0.4247\n",
            "Epoch 141: val_accuracy did not improve from 0.80952\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 58ms/step - accuracy: 0.7340 - loss: 0.4247 - val_accuracy: 0.8094 - val_loss: 0.1102\n",
            "Epoch 141: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Carregando o modelo treinado"
      ],
      "metadata": {
        "id": "rknOwTiod78W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('best_model_NLTK.keras')"
      ],
      "metadata": {
        "id": "paL0Lj181J49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Graficos de acuracia e perda"
      ],
      "metadata": {
        "id": "fvYEK86UeIao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(history.history['accuracy'], label='Treino')\n",
        "plt.plot(history.history['val_accuracy'], label='Validação')\n",
        "plt.legend()\n",
        "plt.title('Acurácia durante o treinamento')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "de2w1_Uv2ibx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "7600ff4b-7562-4ff5-8681-e947b19fc8e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label='Treino')\n",
        "plt.plot(history.history['val_loss'], label='Validação')\n",
        "plt.legend()\n",
        "plt.title('Perda durante o treinamento')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "A6eQRzsNhc-4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "outputId": "934f3bfb-7253-4355-80ea-16cc912b4451"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhYAAAGzCAYAAABzfl4TAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAY3dJREFUeJzt3Xd803Xix/FXkjbpXrSlpRQoUDayUUAFBcU9T04PFXEr7nN7iuOnyOl5jnPfCZ5bVBRR9FABBVmCyN6lpUBbVtO9ku/vj28bKG2hhbQp6fv5eOSR5Jvv+HxDoW8+02IYhoGIiIiIF1h9XQARERHxHwoWIiIi4jUKFiIiIuI1ChYiIiLiNQoWIiIi4jUKFiIiIuI1ChYiIiLiNQoWIiIi4jUKFiIiIuI1ChbS4mzbtg2LxcLUqVMb9Tpz587FYrEwd+7cRr2OHB2LxcLjjz/u62KI+B0FC2lyU6dOxWKxeB5BQUF06dKF2267jezsbF8Xr0X68MMPefHFF31djGrWrl3L448/zrZt23xdFL/y2muvNXqolpYtwNcFkJbrySefJCUlhZKSEubPn8/rr7/Ot99+y+rVqwkJCfF18VqUDz/8kNWrV3PXXXf5uigea9eu5YknnmDEiBF06NDB6+cvLi4mIKDl/RP42muvERsbyzXXXOProoifanl/q6TZOPvssxk4cCAA119/Pa1ateKFF17gq6++4oorrjimcxcVFfldOCkpKcFut2O1qqLxUIZhUFJSQnBwcL2PCQoKasQSibRc+hdKmo3TTz8dgLS0NM+2999/nwEDBhAcHExMTAyXX34527dvr3bciBEj6NWrF8uWLePUU08lJCSEhx9+GIDc3FyuueYaIiMjiYqKYty4ceTm5ta49sqVK7nmmmvo2LEjQUFBJCQkcO2117J37956lT0zM5OLLrqI0NBQ4uPjufvuuyktLa2xX4cOHWr9n+KIESMYMWKE531V/4yPP/6Yv/3tbyQlJRESEkJeXh779u3j3nvvpXfv3oSFhREREcHZZ5/NH3/8Ue2cVef49NNPefrpp2nbti1BQUGMHDmSzZs3V7v2N998Q3p6uqd56uAagtLSUiZOnEjnzp1xOBwkJydz//3313p/tZk2bZrnzzA2NpYrr7ySHTt2HPaYqVOnctlllwFw2mmnecpV1V+lQ4cOnHfeeXz//fcMHDiQ4OBg3nzzTcD8M7/rrrtITk7G4XDQuXNnJk+ejNvtrnaNQ/tYPP7441gsFjZv3sw111xDVFQUkZGRjB8/nqKiomrHTpkyhdNPP534+HgcDgc9evTg9ddfr3EfVeWcO3eup5y9e/f23McXX3xB7969CQoKYsCAAfz+++81zrF+/Xr+9Kc/ERMTQ1BQEAMHDmTGjBk1vi+LxcKCBQu45557iIuLIzQ0lIsvvpjdu3dXK8+aNWuYN2+e5zs9+Odu69atXHbZZcTExBASEsJJJ53EN998c9g/K5FDqcZCmo0tW7YA0KpVKwCefvppHn30UcaMGcP111/P7t27eeWVVzj11FP5/fffiYqK8hy7d+9ezj77bC6//HKuvPJKWrdujWEYXHjhhcyfP5+bb76Z7t27M336dMaNG1fj2rNnz2br1q2MHz+ehIQE1qxZw1tvvcWaNWtYtGgRFoulznIXFxczcuRIMjIyuOOOO2jTpg3vvfceP/300zF/J0899RR2u517772X0tJS7HY7a9eu5csvv+Syyy4jJSWF7Oxs3nzzTYYPH87atWtp06ZNtXM8++yzWK1W7r33XpxOJ3//+98ZO3YsixcvBuCRRx7B6XSSmZnJP//5TwDCwsIAcLvdXHDBBcyfP58bb7yR7t27s2rVKv75z3+yceNGvvzyy8OWf+rUqYwfP55BgwYxadIksrOzeemll1iwYEGNP8ODnXrqqdxxxx28/PLLPPzww3Tv3h3A8wywYcMGrrjiCm666SZuuOEGunbtSlFREcOHD2fHjh3cdNNNtGvXjl9//ZWHHnqIXbt21asfyZgxY0hJSWHSpEksX76cf//738THxzN58mTPPq+//jo9e/bkggsuICAggK+//ppbb70Vt9vNhAkTqp1v8+bN/OUvf+Gmm27iyiuv5Pnnn+f888/njTfe4OGHH+bWW28FYNKkSYwZM4YNGzZ4aqXWrFnDsGHDSEpK4sEHHyQ0NJRPP/2Uiy66iM8//5yLL7642rVuv/12oqOjmThxItu2bePFF1/ktttu45NPPgHgxRdf5PbbbycsLIxHHnkEgNatWwOQnZ3N0KFDKSoq4o477qBVq1a8++67XHDBBXz22Wc1riVSJ0OkiU2ZMsUAjB9++MHYvXu3sX37duPjjz82WrVqZQQHBxuZmZnGtm3bDJvNZjz99NPVjl21apUREBBQbfvw4cMNwHjjjTeq7fvll18agPH3v//ds62iosI45ZRTDMCYMmWKZ3tRUVGNcn700UcGYPz888+HvZ8XX3zRAIxPP/3Us62wsNDo3LmzARhz5szxbG/fvr0xbty4GucYPny4MXz4cM/7OXPmGIDRsWPHGmUrKSkxXC5XtW1paWmGw+EwnnzyyRrn6N69u1FaWurZ/tJLLxmAsWrVKs+2c88912jfvn2Ncr333nuG1Wo1fvnll2rb33jjDQMwFixYUOt3YhiGUVZWZsTHxxu9evUyiouLPdtnzpxpAMZjjz1W57GGYRjTpk2r8f1Vad++vQEY3333XbXtTz31lBEaGmps3Lix2vYHH3zQsNlsRkZGhmcbYEycONHzfuLEiQZgXHvttdWOvfjii41WrVpV21bbz8vo0aONjh071lrOX3/91bPt+++/NwAjODjYSE9P92x/8803a9zvyJEjjd69exslJSWebW632xg6dKiRmprq2Vb1d2rUqFGG2+32bL/77rsNm81m5Obmerb17Nmz2s9albvuussAqv1Z5+fnGykpKUaHDh1q/MyJ1EVNIeIzo0aNIi4ujuTkZC6//HLCwsKYPn06SUlJfPHFF7jdbsaMGcOePXs8j4SEBFJTU5kzZ061czkcDsaPH19t27fffktAQAC33HKLZ5vNZuP222+vUZaD2+ZLSkrYs2cPJ510EgDLly8/7H18++23JCYm8qc//cmzLSQkhBtvvLH+X0Ydxo0bV6PfgMPh8PyP1uVysXfvXsLCwujatWutZR0/fjx2u93z/pRTTgHMau8jmTZtGt27d6dbt27V/hyqmq0O/XM42G+//UZOTg633nprtf4M5557Lt26dTvmKvaUlBRGjx5do7ynnHIK0dHR1co7atQoXC4XP//88xHPe/PNN1d7f8opp7B3717y8vI82w7+M3E6nezZs4fhw4ezdetWnE5nteN79OjBkCFDPO9PPPFEwGz6a9euXY3tVX8u+/bt46effmLMmDHk5+d77mXv3r2MHj2aTZs21WhSuvHGG6vVrp1yyim4XC7S09OPeN/ffvstgwcP5uSTT/ZsCwsL48Ybb2Tbtm2sXbv2iOcQATWFiA+9+uqrdOnShYCAAFq3bk3Xrl09vzA3bdqEYRikpqbWemxgYGC190lJSdV+eQKkp6eTmJjoqdav0rVr1xrn27dvH0888QQff/wxOTk51T479BfFodLT0+ncuXON5pLartNQKSkpNba53W5eeuklXnvtNdLS0nC5XJ7PqpqRDnbwLy+A6OhoAPbv33/E62/atIl169YRFxdX6+eHflcHq/plVtv30K1bN+bPn3/E6x9Obd/Npk2bWLly5VGVt8rhvq+IiAgAFixYwMSJE1m4cGGN/hdOp5PIyMg6z1f1WXJycq3bq/5cNm/ejGEYPProozz66KN13k9SUlK9yn4k6enpnnBzsKrmp/T0dHr16nXE84goWIjPDB482DMq5FButxuLxcKsWbOw2Ww1Pj80LDRkNEBtxowZw6+//sp9991H3759CQsLw+12c9ZZZ9Xo9Hcs6uqr4XK5ar3P2u7rmWee4dFHH+Xaa6/lqaeeIiYmBqvVyl133VVrWWs7L5gjKY7E7XbTu3dvXnjhhVo/P/SXY1Oq7btxu92cccYZ3H///bUe06VLlyOe90jf15YtWxg5ciTdunXjhRdeIDk5Gbvdzrfffss///nPGn8GdZ3vSNepOs+9995bo2amSufOnRt0TpGmoGAhzVKnTp0wDIOUlJR6/TKoTfv27fnxxx8pKCioFkQ2bNhQbb/9+/fz448/8sQTT/DYY495tm/atKne11m9ejWGYVQLDodeB8z/QdY2KiU9PZ2OHTvW63qfffYZp512Gv/5z3+qbc/NzSU2NrZe5zhUXYGnU6dO/PHHH4wcOfKwHVhr0759e8D8HqqaTqps2LDB83lDy3Q4nTp1oqCggFGjRjX42Pr6+uuvKS0tZcaMGdVqCA7XLHQ0qn4eAgMDvXo/dX2v7du3r/Vndv369Z7PRepDfSykWbrkkkuw2Ww88cQTNf63ZRhGvYaBnnPOOVRUVFQbBuhyuXjllVeq7Vf1v7xDr1PfmSjPOeccdu7cyWeffebZVlRUxFtvvVVj306dOrFo0SLKyso822bOnFljCO3h2Gy2GmWdNm3aEYdwHk5oaGitTT5jxoxhx44dvP322zU+Ky4uprCwsM5zDhw4kPj4eN54441qQ1NnzZrFunXrOPfcc49YJqDWIFaXMWPGsHDhQr7//vsan+Xm5lJRUVHvc9Wltp8Xp9PJlClTjvncB4uPj2fEiBG8+eab7Nq1q8bnBw8jbYjQ0NBav9NzzjmHJUuWsHDhQs+2wsJC3nrrLTp06ECPHj2O6nrS8qjGQpqlTp068X//93889NBDbNu2jYsuuojw8HDS0tKYPn06N954I/fee+9hz3H++eczbNgwHnzwQbZt20aPHj344osvavwCjYiI4NRTT+Xvf/875eXlJCUl8b///a/afBqHc8MNN/Cvf/2Lq6++mmXLlpGYmMh7771X6wRd119/PZ999hlnnXUWY8aMYcuWLbz//vt06tSp3t/Neeedx5NPPsn48eMZOnQoq1at4oMPPqh3jUdtBgwYwCeffMI999zDoEGDCAsL4/zzz+eqq67i008/5eabb2bOnDkMGzYMl8vF+vXr+fTTTz3zSNQmMDCQyZMnM378eIYPH84VV1zhGW7aoUMH7r777sOWqW/fvthsNiZPnozT6cThcHjmjqjLfffdx4wZMzjvvPO45pprGDBgAIWFhaxatYrPPvuMbdu2HXWtTpUzzzwTu93O+eefz0033URBQQFvv/028fHxtQaAY/Hqq69y8skn07t3b2644QY6duxIdnY2CxcuJDMzs8bcJfUxYMAAXn/9df7v//6Pzp07Ex8fz+mnn86DDz7IRx99xNlnn80dd9xBTEwM7777LmlpaXz++eeamE3qzydjUaRFqxoat3Tp0iPu+/nnnxsnn3yyERoaaoSGhhrdunUzJkyYYGzYsMGzz/Dhw42ePXvWevzevXuNq666yoiIiDAiIyONq666yvj9999rDDfNzMw0Lr74YiMqKsqIjIw0LrvsMmPnzp01hiTWJT093bjggguMkJAQIzY21rjzzjuN7777rtbhkv/4xz+MpKQkw+FwGMOGDTN+++23OoebTps2rca1SkpKjL/+9a9GYmKiERwcbAwbNsxYuHBhvc+RlpZW4/4LCgqMv/zlL0ZUVJQBVBt6WlZWZkyePNno2bOn4XA4jOjoaGPAgAHGE088YTidziN+N5988onRr18/w+FwGDExMcbYsWONzMzMIx5nGIbx9ttvGx07djRsNlu177J9+/bGueeeW+sx+fn5xkMPPWR07tzZsNvtRmxsrDF06FDj+eefN8rKyjz7HfpnWzXcdPfu3dXOV/XzmpaW5tk2Y8YM44QTTjCCgoKMDh06GJMnTzbeeeedGvvVVU7AmDBhQrVtVX8uzz33XLXtW7ZsMa6++mojISHBCAwMNJKSkozzzjvP+Oyzz2qU8dC/U1U/Awf/DGZlZRnnnnuuER4ebgDVfma2bNli/OlPfzKioqKMoKAgY/DgwcbMmTNrlF/kcCyGoV49IiIi4h2q2xIRERGvUbAQERERr1GwEBEREa9RsBARERGvUbAQERERr1GwEBEREa9p8gmy3G43O3fuJDw8/Kim7BUREZGmZxgG+fn5tGnT5rATpjV5sNi5c6dPFy4SERGRo7d9+3batm1b5+cNChYdOnTwLIV8sFtvvZVXX321XucIDw/3FKxqCWIRERFp3vLy8khOTvb8Hq9Lg4LF0qVLcblcnverV6/mjDPO4LLLLqv3OaqaPyIiIhQsREREjjNH6sbQoGARFxdX7f2zzz5Lp06dGD58eMNLJiIiIn7nqPtYlJWV8f7773PPPfccNr2UlpZWWzI5Ly/vaC8pIiIizdxRDzf98ssvyc3N5ZprrjnsfpMmTSIyMtLzUMdNERER/3XUq5uOHj0au93O119/fdj9aquxSE5Oxul0qo+FiIgfcLlclJeX+7oYcoxsNhsBAQF1tkLk5eURGRl5xN/fR9UUkp6ezg8//MAXX3xxxH0dDgcOh+NoLiMiIs1cQUEBmZmZHOX/UaWZCQkJITExEbvdftTnOKpgMWXKFOLj4zn33HOP+sIiInJ8c7lcZGZmEhISQlxcnCY9PI4ZhkFZWRm7d+8mLS2N1NTUw06CdTgNDhZut5spU6Ywbtw4AgKafH4tERFpJsrLyzEMg7i4OIKDg31dHDlGwcHBBAYGkp6eTllZGUFBQUd1ngbHkR9++IGMjAyuvfbao7qgiIj4F9VU+I+jraU4WIOrHM4880y1pYmIiEittLqpiIiIeI2ChYiIyDGYO3cuFouF3NxcXxelWVCwEBGRFsNisRz28fjjjzf4nEOHDmXXrl1ERkZ6v8DHIb8Z1vHP2RvZU1DK3Wd0ITZM82aIiEhNu3bt8rz+5JNPeOyxx9iwYYNnW1hYmOe1YRi4XK4jjoC02+0kJCR4v7DHKb+psfhwSQYfLM4gO6/E10UREWmRDMOgqKzCJ4/6DipISEjwPCIjI7FYLJ7369evJzw8nFmzZjFgwAAcDgfz58/H7XYzadIkUlJSCA4Opk+fPnz22Weecx7aFDJ16lSioqL4/vvv6d69O2FhYZx11lnVQo3b7ebJJ5+kbdu2OBwO+vbty3fffefVPw9f8Zsai/CgAHbnl1JQUuHrooiItEjF5S56PPa9T6699snRhNi98yvtwQcf5Pnnn6djx45ER0czadIk3n//fd544w1SU1P5+eefufLKK4mLi6tzde+ioiKef/553nvvPaxWK1deeSX33nsvH3zwAQAvvfQS//jHP3jzzTfp168f77zzDhdccAFr1qwhNTXVK/fhK34ULAIByFewEBGRY/Dkk09yxhlnAOZ6V8888ww//PADQ4YMAaBjx47Mnz+fN998s85gUV5ezhtvvEGnTp0AuO2223jyySc9nz///PM88MADXH755QBMnjyZOXPm8OKLL/Lqq6825u01Ov8JFg7zVvJLtRCOiIgvBAfaWPvkaJ9d21sGDhzoeb1582aKioo8QaNKWVkZ/fr1q/McISEhnlABkJiYSE5ODmAu5rVz506GDRtW7Zhhw4bxxx9/eOMWfMp/gkVQZbBQjYWIiE9YLBavNUf4UmhoqOd1QUEBAN988w1JSUnV9jvcApuBgYHV3lsslhYzueTx/xNQScFCRES8rUePHjgcDjIyMups9mioiIgI2rRpw4IFC6qdc8GCBQwePNgr1/AlPwoWZjrMK1FTiIiIeEd4eDj33nsvd999N263m5NPPhmn08mCBQuIiIhg3LhxR3Xe++67j4kTJ9KpUyf69u3LlClTWLFihadz5/HMj4KFaixERMT7nnrqKeLi4pg0aRJbt24lKiqK/v378/DDDx/1Oe+44w6cTid//etfycnJoUePHsyYMeO4HxECYDGauNEnLy+PyMhInE4nERERXjvvf+an8dTMtVzQpw0vX1F3hxoREfGOkpIS0tLSSElJOeoltqV5OdyfaX1/f/vNBFkHaizUFCIiIuIr/hMsHGoKERER8TX/CRaaIEtERMTn/ChYqClERETE1/wwWKjGQkRExFf8KFiYTSEFZRW43S1jdjMREZHmxo+ChVljYRhmuBAREZGm5zfBwhFgJdBmAdDS6SIiIj7iN8HCYrFoZIiIiIiP+U2wAI0MERGRxjdixAjuuusuz/sOHTrw4osvHvYYi8XCl19+6bUyuFwuhg4dSo8ePdiwYQMnn3wyu3fv9tr5j4WfBgvVWIiISE3nn38+Z511Vq2f/fLLL1gsFlauXNmgcy5dupQbb7zRG8Wrt3Xr1hEbG8vkyZO59NJL6dSpE3FxcU1ahrr4zSJkAOEOrXAqIiJ1u+6667j00kvJzMykbdu21T6bMmUKAwcO5IQTTmjQOX3xC71Xr17MmDEDMMNSc6IaCxER8Q7DgLJC3zzquZ7meeedR1xcHFOnTq22vaCggGnTpnHRRRdxxRVXkJSUREhICL179+ajjz467DkPbQrZtGkTp556KkFBQfTo0YPZs2fXOOaBBx6gS5cuhISE0LFjRx599FHKy6v/p/jrr79m0KBBBAUFERsby8UXX+z57L333mPgwIGEh4eTkJDAX/7yF3JycqodP2/ePAYPHozD4SAxMZEHH3yQiorG//3oXzUW6rwpIuI75UXwTBvfXPvhnWAPPeJuAQEBXH311UydOpVHHnkEi8UcTTht2jRcLhdXXnkl06ZN44EHHiAiIoJvvvmGq666ik6dOjF48OAjnt/tdnPJJZfQunVrFi9ejNPprNYfo0p4eDhTp06lTZs2rFq1ihtuuIHw8HDuv/9+AL755hsuvvhiHnnkEf773/9SVlbGt99+6zm+vLycp556iq5du5KTk8M999zDNddc49lnx44dnHPOOVxzzTX897//Zf369dxwww0EBQXx+OOP1+MLPXp+FizM2ykoVVOIiIjU7tprr+W5555j3rx5jBgxAjCbQS699FLat2/Pvffe69n39ttv5/vvv+fTTz+tV7D44YcfWL9+Pd9//z1t2pgh65lnnuHss8+utt/f/vY3z+sOHTpw77338vHHH3uCxdNPP83ll1/OE0884dmvT58+1e6hSseOHXn55ZcZNGgQBQUFhIWF8dprr5GcnMy//vUvLBYL3bp1Y+fOnTzwwAM89thjWK2N12Dhl8FCNRYiIj4QGGLWHPjq2vXUrVs3hg4dyjvvvMOIESPYvHkzv/zyC08++SQul4tnnnmGTz/9lB07dlBWVkZpaSkhIfU7/7p160hOTvaECoAhQ4bU2O+TTz7h5ZdfZsuWLRQUFFBRUUFERITn8xUrVnDDDTfUeZ1ly5bx+OOP88cff7B//37cbjcAGRkZ9OjRg3Xr1jFkyBBPjQzAsGHDKCgoIDMzk3bt2tXrfo6G+liIiIh3WCxmc4QvHgf9Aq2P6667js8//5z8/HymTJlCp06dGD58OM899xwvvfQSDzzwAHPmzGHFihWMHj2asrIyr31NCxcuZOzYsZxzzjnMnDmT33//nUceeaTaNYKDg+s8vrCwkNGjRxMREcEHH3zA0qVLmT59OoBXy3m0/CxYVPWxUFOIiIjUbcyYMVitVj788EP++9//cu2112KxWFiwYAEXXnghV155JX369KFjx45s3Lix3uft3r0727dvZ9euXZ5tixYtqrbPr7/+Svv27XnkkUcYOHAgqamppKenV9vnhBNO4Mcff6z1GuvXr2fv3r08++yznHLKKXTr1q1Gx83u3buzcOFCjIM6tS5YsIDw8PAao2G8zc+ChVljkacaCxEROYywsDD+/Oc/89BDD7Fr1y6uueYaAFJTU5k9eza//vor69at46abbiI7O7ve5x01ahRdunRh3Lhx/PHHH/zyyy888sgj1fZJTU0lIyODjz/+mC1btvDyyy97ahyqTJw4kY8++oiJEyeybt06Vq1axeTJkwFo164ddrudV155ha1btzJjxgyeeuqpasffeuutbN++ndtvv53169fz1VdfMXHiRO65555G7V8BfhcsNCpERETq57rrrmP//v2MHj3a0yfib3/7G/3792f06NGMGDGChIQELrroonqf02q1Mn36dIqLixk8eDDXX389Tz/9dLV9LrjgAu6++25uu+02+vbty6+//sqjjz5abZ8RI0Ywbdo0ZsyYQY8ePRg4cCBLliwB8AyXnTZtGj169ODZZ5/l+eefr3Z8UlIS3377LUuWLKFPnz7cfPPNXHfdddU6jTYWi2HUc/Cvl+Tl5REZGYnT6azWUcUblqXv59LXf6VtdDDzHzjdq+cWEZHqSkpKSEtLIyUlhaCgIF8Xx28tXLiQ1157jffee6/Rr3W4P9P6/v72qxqLCM9wU9VYiIjI8W/9+vVUVFR4Ztk8HvjZcNMDTSGGYVQbZiMiInK8mTBhAgsWLGD8+PG+Lkq9+VmwMG/H5TYoLncRYver2xMRkRamrpEhzZlfNYWE2G3YrGYthTpwioiIND2/ChYWi4UwR9UkWZrLQkSkKTTxGABpRN74s/SrYAGay0JEpKnYbDagecz2KN5RVFQEQGBg4FGfo8GdEHbs2MEDDzzArFmzKCoqonPnzp417JuDAzUWChYiIo0pICCAkJAQdu/eTWBgYKNPvCSNxzAMioqKyMnJISoqyhMaj0aDgsX+/fsZNmwYp512GrNmzSIuLo5NmzYRHR191AXwtojKkSEFChYiIo3KYrGQmJhIWlpajSmp5fgUFRVFQkLCMZ2jQcFi8uTJJCcnM2XKFM+2lJSUwx5TWlpKaWmp531eXl4Di9gwBxYiUx8LEZHGZrfbSU1NVXOIHwgMDDymmooqDQoWM2bMYPTo0Vx22WXMmzePpKQkbr311sMu7Tpp0qRq68k3Nq1wKiLStKxWq2beFI8GNYht3bqV119/ndTUVL7//ntuueUW7rjjDt599906j3nooYdwOp2ex/bt24+50IejFU5FRER8p0E1Fm63m4EDB/LMM88A0K9fP1avXs0bb7zBuHHjaj3G4XDgcDiOvaT1pFEhIiIivtOgGovExER69OhRbVv37t3JyMjwaqGORZiaQkRERHymQcFi2LBhbNiwodq2jRs30r59e68W6lioKURERMR3GhQs7r77bhYtWsQzzzzD5s2b+fDDD3nrrbeYMGFCY5WvwSJUYyEiIuIzDQoWgwYNYvr06Xz00Uf06tWLp556ihdffJGxY8c2VvkaLFxLp4uIiPhMg2fePO+88zjvvPMaoyxeoaYQERER3/G7+Vc1j4WIiIjv+FewMAzCtVaIiIiIz/hPsHj1JHimDeElOwEoc7kpKXf5uFAiIiIti/8Ei/JCKC8itGyvZ5NqLURERJqW/wSLsNYA2IpyDlo6XR04RUREmpLfBQvyszTkVERExEf8L1gU5GhkiIiIiI/4YbDI1lwWIiIiPuJHwSLefC440MdCK5yKiIg0Lf8JFuEJ5nNBFq3C7ADszi/1YYFERERaHv8JFgfVWLSNCgZgR26xDwskIiLS8vhRsDjQeTMpygHAjv0KFiIiIk3Jf4JFaJz57C6nXUgZoBoLERGRpuY/wSLAAcHRALQNyAPMGgvDMHxZKhERkRbFf4IFQJjZgbO11QlAcbmL3CINORUREWkqfhYszA6c9uI9xIZV9rNQc4iIiEiT8bNgcWCSrKSoIAAy1YFTRESkyfhZsKgacppNUrSGnIqIiDQ1/woWnkmyskmqmstCNRYiIiJNxr+CRbWmEDNY7FSNhYiISJPxs2BxYPbNpOgQQE0hIiIiTcnPgsWBGos2lZ03FSxERESajn8Gi+L9tA2zAbCvsIyiMq1yKiIi0hT8K1gER4M1EIAI9z7P8unqZyEiItI0/CtYWCyeWgtLwe4DI0NyS3xZKhERkRbDv4IFVJvLwtPPQkNORUREmoQfBouqDpxZB02SVeTDAomIiLQc/hcswquCRQ5JUZVDTlVjISIi0iT8L1gcPElWdNUkWepjISIi0hT8MFgcNElWlNYLERERaUp+GCxqTuudlVdChcvtw0KJiIi0DH4YLCoXIsvPJj7cQaDNgsttkJWn5hAREZHG5ofB4sBwU6sFEiO1yqmIiEhT8d9g4SqFEueBVU6dChYiIiKNzf+CRWAwOCLN1wU5tIlSjYWIiEhT8b9gAQfNZXFgkqxMBQsREZFG55/BIuzAJFkdY0MB2Lq70IcFEhERaRn8M1iEJ5rPzu10jg8DYGNOPoZh+LBQIiIi/s8/g0VMR/N5Xxqd4sKwWCC3qJy9hWW+LZeIiIifa1CwePzxx7FYLNUe3bp1a6yyHb2YFPN531aC7TaSo801QzZm5/uwUCIiIv4voKEH9OzZkx9++OHACQIafIrGd1CNBUBqfBgZ+4rYnFPA0E6xPiyYiIiIf2twKggICCAhIaExyuI9VcEiLxPKi0ltHc6P63PYlF3g23KJiIj4uQb3sdi0aRNt2rShY8eOjB07loyMjMPuX1paSl5eXrVHowtpBY4I8/X+dFIrO3BuylFTiIiISGNqULA48cQTmTp1Kt999x2vv/46aWlpnHLKKeTn1/0Le9KkSURGRnoeycnJx1zoI7JYqvWzSG1tBovNOaqxEBERaUwNChZnn302l112GSeccAKjR4/m22+/JTc3l08//bTOYx566CGcTqfnsX379mMudL14+llspVOcGSz2FJSxTyNDREREGs0xDTeNioqiS5cubN68uc59HA4HERER1R5N4qBgEeoI8KwZoloLERGRxnNMwaKgoIAtW7aQmJjorfJ4z0HBAvA0h6ifhYiISONpULC49957mTdvHtu2bePXX3/l4osvxmazccUVVzRW+Y5eVbDYf2DIKaCRISIiIo2oQcNNMzMzueKKK9i7dy9xcXGcfPLJLFq0iLi4uMYq39GLruy8mZsBFWWkxocDagoRERFpTA0KFh9//HFjlcP7whMgIBgqisG5ndTWMYCaQkRERBqTf64VApVDTg/0s6hajCw7rxRncbkPCyYiIuK//DdYQLW5LMKDAkmMDALUHCIiItJY/DxYVB8ZUlVrsVnNISIiIo2iRQWLqg6cGzUyREREpFG0rGDhmctCwUJERKQxtIxgsT8d3C66VAaLdbvyMAzDhwUTERHxT/4dLCLagM0O7nJwZtIjMRKb1cLu/FKy8kp8XToRERG/49/BwmqD6A7m631bCbbb6Nra7Gfxx/ZcnxVLRETEX/l3sIAa/Sz6tosC4HcFCxEREa9recGibRSgGgsREZHG4P/BolVn83n3egD6JEcBsCrTicutDpwiIiLe5P/BIqG3+Zy1GjAnyQq12ygsc2kGThERES/z/2AR3wOwQEEWFOzGZrXQu20koOYQERERb/P/YOEIO7BmSPYq4EBzyIrMXN+USURExE/5f7CAGs0hVR04V2Tk+qY8IiIifqplBIvWlcEiuzJYVA453ZCdT3GZy0eFEhER8T8tI1gk9DKfs8ymkISIIOLDHbjcBmt2On1YMBEREf/SQoJFZY3Fno1QUYrFYjnQz0IdOEVERLymZQSLiCQIigJ3hWc+i74KFiIiIl7XMoKFxXJQB06zOaQqWPyhkSEiIiJe0zKCBdQYGdK7bSQWC2zfV0xOvlY6FRER8YaWEyxaV3bgrBwZEhEUSPeECAAWbd3nq1KJiIj4lZYTLDwjQ1aCYa4RMqRTKwAWbtnrq1KJiIj4lZYTLOK6gTUASpzgzARgSEczWCzaqmAhIiLiDS0nWAQ4ILar+bqyOWRwxxisFkjbU0iWU/0sREREjlXLCRZwUHPIgX4WvZLMBclUayEiInLsWliwqBoZstKzqao5RP0sREREjl3LDBa7Vng2nVTVgVM1FiIiIsesZQWLNv3BYoXcDMjbCcCgDjHYrBYy9hWxI7fYxwUUERE5vrWsYBEUcaDWIv1XAMIcAfSu7Geh5hAREZFj07KCBUC7oeZzxkLPJs1nISIi4h0tL1i0H2I+px8ULA6az8KonDxLREREGq7lBYt2lcEiZy0U7wdgYIdoAm0WduQWs32f+lmIiIgcrZYXLMLioVVnwICMxQCE2APolxwNwM+bdvuwcCIiIse3lhcs4ECtRcavnk3Du8YBMGd9ji9KJCIi4hdaZrBoX9mB86B+Fqd3iwdgwZY9lJS7fFEqERGR417LDBZVNRY7f4dys09Ft4RwEiODKCl3a3SIiIjIUWqZwSK6A4QngrscMn8DwGKxcFplrcVPag4RERE5Ki0zWFgsB/WzOKg5pOuBYKFhpyIiIg13TMHi2WefxWKxcNddd3mpOE3I08/iQAfOoZ1bYQ+wsiO3mE05BT4qmIiIyPHrqIPF0qVLefPNNznhhBO8WZ6mU1VjkbkUXBWAOey0arIsNYeIiIg03FEFi4KCAsaOHcvbb79NdHS0t8vUNOJ7QFAklBVUW0b9dPWzEBEROWpHFSwmTJjAueeey6hRo464b2lpKXl5edUezYLVCsknma8zag47XZa+H2dRuS9KJiIictxqcLD4+OOPWb58OZMmTarX/pMmTSIyMtLzSE5ObnAhG41n3ZAD/SySY0LoHB+Gy21oFk4REZEGalCw2L59O3feeScffPABQUFB9TrmoYcewul0eh7bt28/qoI2Cs9Kp4vgoFEgIytrLWavzfZFqURERI5bDQoWy5YtIycnh/79+xMQEEBAQADz5s3j5ZdfJiAgAJer5oyVDoeDiIiIao9mo00/CAiCoj2wZ5Nn85k9EwBzeu/SCs3CKSIiUl8NChYjR45k1apVrFixwvMYOHAgY8eOZcWKFdhstsYqZ+MIsEPSQPP1QeuG9EuOIj7cQX5pBb9qFk4REZF6a1CwCA8Pp1evXtUeoaGhtGrVil69ejVWGRuXp5/FgQ6cVquF0ZW1Ft+vzvJFqURERI5LLXPmzYPVstIp4AkWs9dm43JrFk4REZH6CDjWE8ydO9cLxfCh5MFgsUJuBjh3QGQSACd2jCEyOJC9hWX8tm0fJ1ZOnCUiIiJ1U42FIxwS+5ivD5rPItBmZVT31gB8t0bNISIiIvWhYAEHhp2mH9ocYgaL71dnaVEyERGRelCwgAMdOA+qsQA4tUscwYE2djpLWLXD6YOCiYiIHF8ULOBAB86ctVC0z7M5KNDGad3iAPhOo0NERESOSMECIDQWYruYrw+ptagaHfLtql1qDhERETkCBYsqKcPN5y0/Vds8qntrggKtbNtbxMpMNYeIiIgcjoJFlU6nm8+HBItQRwBn9DBrLb5asbOpSyUiInJcUbCo0uFksAbAvq2wL63aRxf0aQPAzJU7NVmWiIjIYShYVAmKgLaDzddb51T7aHiXOCKDA8nJL2XxVq0dIiIiUhcFi4PV0RxiD7ByTm81h4iIiByJgsXBqoLF1p/BVVHto/Mrm0Nmrd6lpdRFRETqoGBxsDZ9ITgaSp2wc3m1j05MaUXrCAd5JRXM27DbN+UTERFp5hQsDma1QccR5utDmkNsVgvnn2DWWnz1h5pDREREaqNgcag6+lkAXNjXXPn0h7XZOIvLm7JUIiIixwUFi0N1PM18zvwNinOrfdQrKYIurcMorXAzQ7UWIiIiNShYHCoq2Zze23DBtl+qfWSxWBgzMBmAT5du90XpREREmjUFi9ocpjnkkv5tCbRZWLXDydqdeU1cMBERkeZNwaI2hwkWMaF2zujRGoBPf1OthYiIyMEULGrTfhhYA2H/NnOK70NUNYdM/30HJeWa00JERKSKgkVtHGHQ7iTzdS21FqekxtEmMghncTn/W5vdxIUTERFpvhQs6tKpcnTIljk1PrJZLfxpQFtAnThFREQOpmBRl6p+Fmk/g6vmnBWXVTaHzN+8h4y9RU1ZMhERkWZLwaIuCX0gOAZK88w5LQ6RHBPCqV3iAHh/cXpTl05ERKRZUrCoi9V6UHNIzX4WAOOGtAfgk6XbKS5TJ04REREFi8M5zLBTgBFd40mOCcZZXM5XK3Y0YcFERESaJwWLw6ma3nvncijaV+Njm9XCVSeZtRbvLkzHMIymLJ2IiEizo2BxOJFJENcNDLfZibMWYwYmExRoZd2uPJZu29/EBRQREWleFCyOxNMc8mOtH0eF2LmoctXTdxdua6JCiYiINE8KFkfiCRZzoI6mjquHdADgu9VZZDlLmqhgIiIizY+CxZG0HwY2Bzi3w56Nte7So00EgzvE4HIbTPk1rYkLKCIi0nwoWByJPQTaDzVfb669OQTgxlM7AvDBogycRTUn1BIREWkJFCzqo/Mo83nzD3Xucnq3eLolhFNQWsF/1ddCRERaKAWL+qgKFukLoLy41l2sVgu3jOgEwDsL0igqq2iq0omIiDQbChb1EdcVIpKgosQMF3U4t3ci7VuFsL+onI+WaHEyERFpeRQs6sNigc4jzdeH6WcRYLNy83Cz1uLtn7dSWqFpvkVEpGVRsKivTlXBou5+FgCX9E+idYSDrLwSvliuab5FRKRlUbCor44jwGIzh5zmZtS5myPAxg2nmCNE/vXTZtVaiIhIi6JgUV/BUdB2kPn6MM0hAFee1J7WEQ525BbzsfpaiIhIC6Jg0RCd69ccEhRo47bTUwH415zNWlJdRERaDAWLhqgKFlvn1TnstMqfBybTNjqY3fmlWkNERERajAYFi9dff50TTjiBiIgIIiIiGDJkCLNmzWqssjU/if0gsh2U5cOGbw+7qz3Ayl2jugDw+twt5JVoNk4REfF/DQoWbdu25dlnn2XZsmX89ttvnH766Vx44YWsWbOmscrXvFitcMIY8/Ufnxxx94v7JdE5PgxncTn//kVriIiIiP9rULA4//zzOeecc0hNTaVLly48/fTThIWFsWjRosYqX/PT53LzefMPUJBz2F1tVgv3nGHWWrz981ay87TyqYiI+Lej7mPhcrn4+OOPKSwsZMiQIXXuV1paSl5eXrXHcS02FZIGgOGC1Z8fcfezeyXQv10UxeUuJn+3vgkKKCIi4jsNDharVq0iLCwMh8PBzTffzPTp0+nRo0ed+0+aNInIyEjPIzk5+ZgK3CycUFlr8cdHR9zVYrEw8fyeAHyxfAcrtuc2YsFERER8q8HBomvXrqxYsYLFixdzyy23MG7cONauXVvn/g899BBOp9Pz2L7dD+Z16HUpWANg1x+Qc+RaiD7JUVzSPwmAJ79eg2EYjV1CERERn2hwsLDb7XTu3JkBAwYwadIk+vTpw0svvVTn/g6HwzOKpOpx3AttBalnmq9XflyvQx44qxshdhvLM3KZ8cfORiyciIiI7xzzPBZut5vS0lJvlOX4csKfzeeVn4LbfcTdW0cEcWvlsurPzlpPYamWVRcREf/ToGDx0EMP8fPPP7Nt2zZWrVrFQw89xNy5cxk7dmxjla/56nIWBEVC3g7Y+lO9Drn+lI4kxwSzy1nCiz9sbOQCioiINL0GBYucnByuvvpqunbtysiRI1m6dCnff/89Z5xxRmOVr/kKDDrQifO3KfU6JCjQxpMX9ALgnQXbWLvzOB8hIyIicgiL0cQ9CfPy8oiMjMTpdB7//S1y1sFrJ5mrnt69GiLa1OuwWz9YxrersujXLorPbx6K1Wpp5IKKiIgcm/r+/tZaIccivju0G2rOabH8vXof9th5PQlzBPB7Ri4fLql7CXYREZHjjYLFsRp4rfm8/F1w1a9DZkJkEH8905yRc/J368nJ14ycIiLiHxQsjlWPCyCkldmJc/Pseh929ZAO9E6KJL+kgkemr9bcFiIi4hcULI5VgAP6/sV8/ds79T7MZrXw9z+dQIDVwuy12ZrbQkRE/IKChTcMGG8+b5oN+9PrfVj3xAhuPz0VgIkz1qhJREREjnsKFt7QqhN0HAEYsPTfDTr01tM60bNNBLlF5WoSERGR456ChbeceLP5vOxdKC2o92GBNivPX9bH0yTy5YodjVRAERGRxqdg4S2poyGmE5Q6YcWHDTq0e2IEd4w0m0Qe+3INmfuLGqOEIiIijU7BwlusVjjpFvP14tfrtX7IwW4d0Yn+7aLIL63gnk//wOVWk4iIiBx/FCy8qc8V5voh+7bCxu8adGiAzco//9yXULuNJWn7ePPnLY1USBERkcajYOFNjjAYcI35etFrDT68fatQJl7QE4AX/reRVZlOLxZORESk8SlYeNvgG821Q7b9ArtWNvjwywa05exeCVS4DW7/aDn5JeWNUEgREZHGoWDhbZFtoedF5usFLzb4cIvFwqRLepMUFcy2vUU88PlKDUEVEZHjhoJFYzj5bvN59eeQtarBh0eF2PnXX/oRaLPw7aospv66zbvlExERaSQKFo0hoTf0vMR8/dPTR3WKfu2iefic7gA88+06fs/Y763SiYiINBoFi8Zy2iNmX4uNs2D70qM6xTVDO3B2rwTKXQYTPljO7vxSLxdSRETEuxQsGktsZ+h7hfn6pyeP6hQWi7lQWcfYUHY6S7jl/WWUVTRsfgwREZGmpGDRmIY/ADY7pP0MW+ce1SnCgwJ5e9xAwh0B/Ja+n4kztJ6IiIg0XwoWjSmqHQy81nz9w+MNno2zSqe4MF6+oh8WC3y0ZDvvLar/CqoiIiJNScGisZ3yV7CHwc7fzVEiR+m0bvE8cFY3AJ74ei2/bNrtrRKKiIh4jYJFYwuLPzD89IfHobz4qE9106kdubhfEi63wa3vL2dDVr53yigiIuIlChZNYcgEiGgLeZmw8NWjPo3FYuHZS3szuEMM+aUVXDt1KTn5JV4sqIiIyLFRsGgKgcEw6nHz9fx/QkHOUZ/KEWDjzasGkBIbyo7cYq5/9zeKyiq8U04REZFjpGDRVHpdCm36Q1kBzDm6SbOqRIfamXLNIKJDAlmZ6eSG//5GSbnLSwUVERE5egoWTcVqhdHPmK+X/xey1x7T6TrEhvKfawYRarexYPNebnxvmcKFiIj4nIJFU2o/BHpcCIYb/ve3Yz5d/3bRTBk/mOBAGz9v3M2ED5ZrAi0REfEpBYumNupxsAbClh9h0w/HfLrBKTH8Z9xAHAFWflyfw+0fLafcpXAhIiK+oWDR1GI6wok3ma//9wi4jr3j5dDOsbx99UDsNivfr8nm7k9WUKFwISIiPqBg4Qun3gfBMbB7Pfz+X++cskscb1zVn0CbhZkrd3HfZytxuTX1t4iINC0FC18IjoIRD5mvf3oaSpxeOe3p3Vrz6l/6E2C1MP33Hdz32R+quRARkSalYOErA8dDq1Qo2mOGCy85s2cCL1/RD5vVwhfLd3DnxyvUoVNERJqMgoWv2ALhnOfM10vegh3LvXbqc3on8upfzGaRb1bt4ub3NRRVRESahoKFL3U6DXqPAQyYeZdXOnJWOatXAv8eN4igQCs/rc9h3DtLcBaXe+38IiIitVGw8LXRT0NQJOz6A5a+7dVTD+8Sx7vjBxPmCGBx2j4uff1Xtu8r8uo1REREDqZg4Wth8TDqCfP1T/8Hzh1ePf2JHVvxyU0nkRARxOacAi56dQHLM/Z79RoiIiJVFCyag/7jIPlEcx2RL28Gt3f7Q/RsE8mXE4bRIzGCvYVlXPHWIr5dtcur1xAREQEFi+bBaoULX4XAUEj7GX55weuXSIgMYtrNQzi9WzylFW5u/WA5b87bgmForgsREfEeBYvmIjYVzqsMFHOfgW0LvH6JUEcAb189kGuGdgBg0qz1PDx9laYAFxERr1GwaE76XA59x5qLlH1+HRTu8folbFYLj1/Qk4nn98BqgY+WbGfsvxeTk1/i9WuJiEjL06BgMWnSJAYNGkR4eDjx8fFcdNFFbNiwobHK1jKd8xzEdoH8XfDVBGikporxw1J466qBhDkCWJK2j/Nfmc+y9H2Nci0REWk5GhQs5s2bx4QJE1i0aBGzZ8+mvLycM888k8LCwsYqX8tjD4U/TQGbHTZ+B8u9s5ZIbUb1aM2M24aRGh9Gdl4pf35zEe/+uk39LkRE5KhZjGP4LbJ7927i4+OZN28ep556ar2OycvLIzIyEqfTSURExNFe2v8teBlmPwr2MLh5PsSkNNqlCksruP/zlXyz0hwpcnG/JJ65uDfBdlujXVNERI4v9f39fUx9LJxOc/GsmJiYOvcpLS0lLy+v2kPqYcgEaD+scgjqLV4fgnqwUEcA/7qiH387tzu2ygXMLn5tAel7VRMlIiINc9TBwu12c9dddzFs2DB69epV536TJk0iMjLS80hOTj7aS7YsVhtc9JpZY5GxEH59uVEvZ7FYuP6Ujnxw/YnEhtlZn5XPeS/P56sV3p2wS0RE/NtRN4XccsstzJo1i/nz59O2bds69ystLaW0tNTzPi8vj+TkZDWF1Nfy92DGbWCxwmVToceFjX7JLGcJt3+0nKXbzBk6L+mfxJMX9iLMEdDo1xYRkeapUZtCbrvtNmbOnMmcOXMOGyoAHA4HERER1R7SAP2uhP5Xm0NQP7sONv3Q6JdMiAzioxtO4q5RqVgt8MXyHZz78i8sSdOoERERObwGBQvDMLjtttuYPn06P/30EykpjdehUCpZLHDei9DzYnCXwydXQvqvjX7ZAJuVu0Z14ZObhpAUFUz63iL+/NZCHp+xhqIy763CKiIi/qVBwWLChAm8//77fPjhh4SHh5OVlUVWVhbFxcWNVT4Bs7/FxW9B5zOgohg+/DPs3dIklx7UIYZZd53C5YOSMQyY+us2zn7pFxZv3dsk1xcRkeNLg/pYWCyWWrdPmTKFa665pl7n0HDTY1BeDP+9CLYvgoQT4LrZEBjUZJeft3E3D32+kp1Oc5bOa4Z24P6zuhJiV98LERF/V9/f38c0j8XRULA4Rnk74fVhULwPBt9oztTZlJcvKWfSt+v4aMl2ANrFhDDpkt4M6xzbpOUQEZGm1STzWIgPRLSBS94yXy95C9bOaNrLBwUy6ZIT+O+1g2kTGUTGviLG/nsx93yygr0FpUc+gYiI+DUFi+NR6hkw7E7z9Ve3wZ7NTV6EU7vE8f3dpzJuSHssFvji9x2MfGEeny7drinBRURaMAWL49Xpj0LbQVDqhP9eAPvSmrwI4UGBPHFhL6bfOozuiRHkFpVz/+cr+fNbi9ick9/k5REREd9TsDhe2QLh8o8gtivk7YB3z4f96T4pSt/kKL6+bRiPnNOd4EAbS9L2cfZLv/CP/22guKzxpiIXEZHmR8HieBYWB+NmQKvO4NwO754Hudt9UpQAm5UbTu3I7HtO5fRu8ZS7DF75aTMj/zGXmSt3qnlERKSFULA43oUnwLivIToFcjPggz9Bca7PitM2OoT/jBvIG1f2JykqmJ3OEm778Hcuf2sRa3dqAToREX+n4ab+Inc7/OcMyN8FHU6BK7+AALtPi1RS7uLNeVt5fd5mSsrdWC3wlxPb8dczuhId6tuyiYhIw2i4aUsTlQxjp4E9HLb9AjNuBx83PwQF2rhzVCo//nUE556QiNuA9xdlMOL5ufz7l62UlKv/hYiIv1GNhb/Z/AN8MAYMFwy9A8540lxvpBlYuGUvT3y9hvVZ5oiRpKhg7j6jCxf3S8JmbR5lFBGR2mnmzZZs+X/NGgswV0c970VzFEkzUOFy8/nyTP45exNZeebU4F1bh3P/WV05vVt8ndPGi4iIbylYtHTLpsLMu83l1lPPhMumgj3U16XyKCl3MfXXbbw2ZzN5JeZqqYM6RPPAWd0Y2CHGx6UTEZFDKVgIbJgF08abK6Im9oHL3oWY5rXUvbOonNfmbWbqgm2UVrgBGN4ljrvP6ELf5CjfFk5ERDwULMS0fSl8OMZctMwRAee/CL0u9XWpatjlLOalHzYxbVkmLrf5Izmqezx3jepCr6RIH5dOREQULOSA3O3w+fXmcusA/ceZq6IGOHxbrlqk7y3k5R83M/33TCrzBWf1TOCuM1LplqCfFxERX1GwkOpcFTDvWfj5ecCAlOFw+QfgCPd1yWq1ZXcBL/+4iRl/7PSMmh3VvTW3jOjEgPbRvi2ciEgLpGAhtdv8I3x6NZQVQJt+MPZzCG3l61LVaWN2Pi/+sJFvV2V5tg3uEMPNIzpyWleNIhERaSoKFlK3Hcvg/T+Z/S5apcJV080JtpqxzTkFvPXzFqb/voNyl/kj27V1ODcN78j5fdoQaNNcbyIijUnBQg5v90Z472LIy4SIJDNcxHX1damOKMtZwjsL0vhgUTqFlSunJkUFc/0pKfx5UDIh9gAfl1BExD8pWMiROTPNcLFnIwRHw9jPoO1AX5eqXpzF5by/KJ0pC9LYU1AGQHRIIFcP6cC4oR2I0VokIiJepWAh9VO4Fz68zGweCQyFP70DXc/ydanqraTcxWfLMnn7l62k7y0CIDjQxp8HJXP9KSm0jQ7xcQlFRPyDgoXUX2kBfHIlbJ1jvh98o7nGSGCwb8vVAC63wazVu3hj3hZW7zCXZ7dZLZzVK4Frh6VoJImIyDFSsJCGqSiD2Y/C4jfM93Hd4NJ/Q0Jv35argQzDYMHmvbwxbwvzN+/xbO+THMXYwe0494REQh3qhyEi0lAKFnJ0Nv0AX94ChTlgDTBXSB1+/3FVe1Fl3a48pixI48sVOymrnC48xG7jvBMS+cuJ7TVluIhIAyhYyNEr3ANf3wnrZ5rvYzqaK6R2HO7TYh2tPQWlfPrbdqb9lknankLP9j5tIxk3tAPnnpCII8DmwxKKiDR/ChZy7NZ9Dd/eB/m7zPd9x8KZ/wchx+fqo4Zh8Fv6fj5anMHMlbsoc5m1GK1C7VwxuB1jT2pHYuTxVzMjItIUFCzEO0qc8OOTsPQ/gAEhreCsZ6H3ZXAcz3q5p6CUj5dk8P6iDLLySgCzs+cZ3VvzpwFtGd41TpNuiYgcRMFCvCtjsdk8snud+b7vlXDeC81yIbOGqHC5+d/abN79dRuL0/Z5trcKtXNB3zZc2r8tPdtEaOpwEWnxFCzE+yrKYMGLMHcSGG5oOxj+/D6Et/Z1ybxifVYe037L5KsVOzyTbgF0aR3GJf3b8qcBbYkNO76DlIjI0VKwkMaz+Uf4bLzZTBLeBi58BTqNPK6bRg5W4XLzy6Y9fLY8k9lrsz0jSuw2K+f3acP4YR3olRTp41KKiDQtBQtpXHu3wEdXwJ4N5vsOp8CoJ6DtAN+Wy8ucxeV8u2oXHy/J4I9Mp2d7l9ZhnJIaxympsZzUsRVBgRpVIiL+TcFCGl9JntkssvTf4KpsOuh5MZzxVLNfLfVoLM/Yz9QF2/h21S4q3Af+2oQ7ArikfxJ/ObE9XRPCfVhCEZHGo2AhTSc3A+ZMgj8+AgwICIaT74ZhdxyXE2sdSW5RGQs27+WXTbuZt3E3u5wlns8GtI/mgj5tOLt3AvHhQT4spYiIdylYSNPLWgWzHoD0Beb76A5w8VvQ7kSfFqsxud0GC7bs4YNFGcxel42rsibDaoETU1pxXp9Ezu6VqNVWReS4p2AhvmEYsGY6/O9vkLcDLFY49X449T6w+fcaHdl5JXz9x05mrtzFiu25nu02q4WhnVoxqntrTkmNJSU2VMNXReS4o2AhvlXihG/uhVWfmu+TBsK5/4A2fX1arKayfV8R36zaxcyVOz2rrVZJigpmZPd4LuqXRL/kKIUMETkuKFhI87DqM5h5D5Q6AQv0uxJGPgZh8b4uWZNJ21PId6uz+GXTbn7btt8zlThA+1YhnHdCIqd3i6dvcjQ2q0KGiDRPChbSfDgzYfZEWP2Z+d4eDqfeCyfdctzP3NlQxWUuFm7dw9d/7OL7NVkUlbk8n0UGB3JqlzhGdInj1C5xxIW3rO9GRJo3BQtpfjIWw3cPwM7fzffRKeaiZt3O9ZvJtRqiqKyC2Wuzmb02m1827cFZXF7t895JkZzWNY7hXePpmxyl2gwR8SkFC2me3G5Y+TH88AQUZJnbEvvCiTdBz0sgsGUO0axwuVmxPZe5G3Yzd2NOjX4ZUSGBnJIax2ldzdoMTS0uIk1NwUKat9ICmP8CLHwVKirngQhpBYNvgiETwBHm2/L5WE5+CfM27Gbuxt38snE3eSUVns8sFrM2Y0TXeEZ0jaNPW9VmiEjja7Rg8fPPP/Pcc8+xbNkydu3axfTp07nooou8XjBpIQr3wvJ3zWXZ8zLNbWGt4bSHzRVU/XyIan1UuNz8vj2XuRtymLthN2t2Vq/NiK6szRih2gwRaUSNFixmzZrFggULGDBgAJdccomChXiHqwLWfQU/Pgn7t5nb4rrDGU9C6hktsg9GXXLySpi7cTfzNuzm5027yT+oNgPMdUwGp8QwqEMMg1NiSIz0v9lPRaTpNUlTiMViUbAQ76oog9/+A/MmQ/F+c1vKqWYnz8Q+vi1bM1ThcrM840BtxtpdeTX2SY4JZlCHGE6sDBuaoEtEjkazCRalpaWUlpZWK1hycrKChRxe8X745R+w+M0DC5x1HAGDboAuZ6mJpA57C0pZum0/S9L2sXTbPtbsdOI+5G94bJiDwSnRDO4Qw6CUGLolRKiPhogcUbMJFo8//jhPPPFEje0KFlIv+9Php6dg9edgVE4sFZkMg2+EAddAkH6GDie/pJzlGbksTdvHkrR9rMjMpazCXW2f8KAABraPZlCKWavROykKe4DVRyUWkeaq2QQL1ViIV+xPh9/egeX/heJ95jZHhBkuhkyA8ASfFu94UVLuYmWmk6Xb9rE4bR/L0/dTUFq9j4YjwErf5Ciz6SQlhv7togl1qIZIpKVrNsHiaAsmUqvyEnP9kV9fgT0bzW2BIXDSrTDsTtVgNFCFy826Xfks2bbPrNXYto99hWXV9rFZLfRqE0G/dtH0SIyge2IEqa3DCAq0+ajUIuILChbi39xu2PS92Q8jc6m5LaQVDL0D+v6lRa1F4k2GYbBld6Gnj8aStH3syC2usV+gzUKPNpH0bxdF/3bRDGgfTZsojT4R8WeNFiwKCgrYvHkzAP369eOFF17gtNNOIyYmhnbt2nmtYCL1YhiwfqY5k+feTeY2iw1Sz4S+V5jPgfqFdyx25BazNG0fq3Y4Wbcrj7W78sgtKq+xX0JEEP3bm0GjX7toeiVF4AhQrYaIv2i0YDF37lxOO+20GtvHjRvH1KlTvVYwkQZxVcAfH8GyqbDjtwPb7WHmKJKeF0OX0WAL9FkR/YVhGGTuL2Z5xn6Wpe9necZ+1u3Kx3XI8BO7zUrn+DA6xYfRKS6Ubgnh9EmOIiEiSMNdRY5DmtJbWq7dG2DFB7Dq8wOzeQKEJ8Kg62DAeAiN9V35/FBRWQUrM50sz9jP8vRcfs/Yz95D+mpUiQ93cELbKLomhNGldTip8eF0jAtVnw2RZk7BQsQwIPM3WPslrPwUCnPM7TY79B0Lp/wVopJ9WkR/ZRgG2/cVszE7ny27C9icU8CanXlsyK5ZswFgtUD7VqGkxleGjdbmc8e4UDWniDQTChYiB6sohbVfweI3YMcyc5s1EPpfDSfeDLGpmja8CRSVVbBmZx6rdzjZlFPApux8NmYX1FgyvorVAh1ahXqCRmrrcLq0DiMlVoFDpKkpWIjUJf1XmDsJ0n4+sC0yGToOh85nmB0+7SG+K18LYxgGu/NL2ZhdwMbsfDbl5LOp8nXeIeugVLFZLbRvFUKXeDNomIEjnJTYUE3uJdJIFCxEjmTbAnPp9rSfD0wbDua8GF3Ogl6XmiEjwO67MrZghmGQk1/KxspajU3Z+WzKMQPHoQuvVQmwWugQazappLYOp1NcKElRwSRFBxMfHqSpy0WOgYKFSH2VFULGQtgyB9Z9DbnpBz4LaQUnXA79r4L47r4ro3gYhkF2XlXgqKzdyMlnc3YB+aW1Bw4Ae4CVrq3D6Z4YTreECFJiQ2nfKoS20SGq5RCpBwULkaNhGLBzOaz+AlZ9BgVZBz6L7wk9L4IeF0FcF1+VUOpgGAZZeSWe2o2N2fmk7y1iR24xu5wltXYaBbMfR2JkMO1bhdC+VQjtYkIrn0PoEBtKmKYzFwEULESOnasCNv8Av78HG78D90H/G247GIbdAV3PBav+t9vcVbjcZO4vZt2uPNZl5bMhK4/0vUVk7CuiqMx12GMTI4PM+TjiwmgbHUxiZDCJUUEkRQUTF+bAquYVaSEULES8qWgfbPgW1nwJW+ccCBmtOkP/cdB+GCSeoAm4jjOGYbCnoIz0vYWk7y0ifV8RGXsLK5+L6pyLo0qA1ULrCDNkJEYFkRgZTFLlc1X4iAwO1IRg4hcULEQaS342LHkTlv4bSpwHtgcEQ9IAaHciJJ8EyYMgONp35ZRj5iwqZ/PufDbnFLB1dyE7nSXsyi1mZ24x2fmldTavHCw40OYJGYmRVeHjQBBpExVEiF3NLdL8KViINLbSfFjxIWz5CbYvhuL91T+3WCHlVOj1J+h+PgRH+aSY0jgqXG52F5SyM7eYnbkl7HKazzsr+3TszC0+Yo1HlaiQwFprO9pEmX0/4sIcqvUQn1OwEGlKbre5CFrGIjNkZCyEfVsPfG6zm0NXe11qDmXVPBktQkm5i6zKkOGp7XBWDyIFhxnJUiXEbqNdTAgxoXYigwOJCAqkVZiduHAH8eFBxIU7Kl87CFVnU2kkChYivrZvK6z+3Bxdsnv9ge32MOh0ulmbkXIqxHbRrJ8tWF5JObtyq8JHcbXXmfvNZpd6tLh4hNhtxFcGjbhwB7FhDlqFOogNt9Mq1EFc5XNsuINQu001IVJvChYizYVhQPYaWP2ZGTRyM6p/HtYaOpxihoz2wyCmo0aaiEdZhZvM/UVs319MblEZzuJynEXl7C0sIye/hN35peTkl5KTV0px+eFHuBzKEWAlNsxBbJjdDCCe55rbokPsmmCshVOwEGmODMNcq2TrHHPGz+1LoKKk+j6BIRDX1Zw3o/NISD0DHOG+Ka8cVwpKK8ygkVfC7gIzbOwtLGVvQRl7CkrZU1DG3sJS9uSXNTiEWC0QE2qvVvtRFTziqoUSO9EhdkJUG+J3FCxEjgflJZC5FLb9Amm/mKHDVVp9H5vDDBjdzzf7Z4TE+Kas4leKyirYk1/GnsJS9uSXsrewzPO8u6CUvQUHAsn+otoXiTscu81KVEgg0SF2z3N0aCBRIXaiQwKJCT0QSqJCAgmxBxAUaCUowKa5QZopBQuR45GrAvZvg5y1ZuBYP7N6J1BrgNls0nkktO5lPsLifFZcaRnKXW72F5axpzJoVNV67DmoNuTg5zKX+5iuFxNq9zTFRAQFEuKwEWoPICokkPiIIBIigogNMzuyRgYHEhEcSKBNzYeNTcFCxB8Yhhky1n1tPrJX19wnsh10Pdus0Wg3BGwaFSC+YxgGRWUu9heVkVtUzv6iMvYXlZNbVMb+wvLK7WXsLSxjb2XTzP6icsoqji2MhNhtnhEzZtgIICI4kOBAG/YAK3ablWC7rbLmxKw1qapNiQm1ExyoppsjUbAQ8Ud7t5i1GJm/mSFjXxpw0F9hexjYQ8FiM2cBTewDHUeYj5iOGn0izZbLbVBa4aKw1MW+wjJ255eyp6CU/NIKikorKCytYF9RGdl5pWTnlbAnv5S8kop6DdetD3uA1RM2IoICCXXYCAsKJMxhI8wRQKgjgDBHAOFBAYQHBRLmCCAsKICIoADCHIGEBQUQEujfzTgKFiItQWmB2T9j3UzY8E3NSboOFhpX2XzSExJ6m69ju2hZeDmuVbjcFJRW4CwuJ6+4gryS8srX5nNxuYtyl5uyCjcFpS6z5qRa7Un5MTfdVLFYMEOIPYAQu41gu63y2QwdIQ4bEUFm001EUEDls1m7EuYIIKTyuFB7ACEOW7Nr3lGwEGlpXBWwdzO4ysBwmaEjYxFsnWtO2uWupQOeNRASekHPS6D3ZRCR2OTFFvGlQ5tu9hWWUVBq1oQUlJg1JVXv8yvf55dUkF9aQX5JuWd7faZ3byi7zUqIw1YZSsxak5iQQKJD7cSE2AkMsGK1gNViIdh+ILREBgcyuEMMwXabV8ujYCEiB5QVQc46yF4FWavNZpTsNVCad2AfixU6nAyh8eZ/vSw2CE8wm1BadYKYTuZ7NaeIVGMYBiXlbvJLy8kvqaCo1EVxuYuisgqKy1wUlbkoKndVhpIDNSt5xeXklVSQV1xOUZmLwjLzWG/UoCx86HQSI4O9cHcH1Pf3t3p5ibQE9hBoO8B8VDEMyE031zr542OzViPt58OfJzDEDBrxPczOoqlnQKB3//ESOd5YKmsMgu024r0w5UxZhdsMJOUVFJaaAaWw1EV+idl8s7fQrF2pcBm4DcNT63KgGaiCyGDfrbSsGgsRMe3dYk7c5SoHw20uDe/MNLfv22rOGGocMqlSYCikjjI7icZ1Nyf2imqn5eNF/JBqLESkYVp1Mh91qSgzw8W+LWbNxtoZ4MyAtV+ZjyoWK0QkQVR7c44NRwQERUJ4IrTuYc4oqrk3RPyWaixE5OgYBuxYbtZy7N5gLrS2ZxNUFB/52NA4c3RKfE+I72aGjpBWEBprvlaNh0izo86bItL0DAMKcsy+G7kZULQXSpxQnGtuy1lbc+6NQ1lsENkWojtAfHdo0x+SBmhxNhEfU1OIiDQ9iwXCW5uP5MG171NWCDnrIWcNZK+FPRuhcLcZQgp3m8Nlc9PNR9q8A8cFhkBkMkQlm7UagcFgs0OAw1whNrKt2QQT2das/dDoFRGfULAQkaZlD605QqWKYUB+FuxPM2s2slaZC7NlrYTyItizwXwcSUBQZchIMsNI1euItmbwiEzSirEijUTBQkSaD4vFnKQrIhHaDz2w3VVuNq3kZoBzO+Rnm6vAusqgvBjyd4FzB+TtgIJscyn6fVvMR10ckQdCRkisuWpscLQ5V0dUuwOBRDOTijSIgoWINH+2wCOPWqlSUQp5O82Q4cw0H57XOyAv0+z3UeqEHKfZJHM49jAIjoHgqMrwURlAQmPNQBLaymx6CYk1tzkizOYZq3dnPRQ5XihYiIh/CXBATIr5qEtp/oGQ4dxh9u8o3g9F+yB/J+RuN2tHXKVQVmA+nBkNK4fFavYLCY4+EERapZqjYOK6mU0xFqv5CIoy+4moc6r4AQULEWl5HOHmL/j4bnXv43ZDSa4ZOKpCR/G+ytd7Kzub7jnoeY+5T9WIF8N9UCjZbm7b8lPd17MGms0y9nCzRqXEaa7vEtPJnHgstotZO+KIhKCIyvlBKp+Do8ER5q1vR+SYKFiIiNTGajWbPkJi6n+M22X2+XCVmY+ywgPBJD/LnOtj93pzJExFqRk+DLc5HNddDvu31Txn9irzcSSBIeb8IMHRdYyIsZj9R6Ira3MCQ8y+KBWlYA0wP4toY9acBEWYAUc1KHIUFCxERLzFaju6mgNXBRRkmU0wZYVmf46gSMACezeZYWTvZjOAlOZBSV71Z1eZOWqmapiut9jDK2tFws2aEZvdDBsWmznyxhFu3m9AkNnB1lUGGGbACU80w0rVc1hrTXzWQihYiIj4mi2gcoRK25qfxXaGrmcf/vjSAnM0TOFuswmFWmosDJfZgXX/NvPhKqucByTIrLnIzzIfBdlm7QlAWb758JaAYLN2xGqrfA4ww8bB7z2fBx7yPsCcuyQo0nxUTRUfFGFuL841m6pK8swg0yrV/O5CYs37rLqONDoFCxGR450jzHzUZ9TMkRiG2TxycI1IaZ7Z4dVVZn7udplhpDTf7ENSUVJZm1FZI1GYYw4Brgor+VlmWKnPdO+NyWI7EDJsgQe9toPNYb4OcAAWs4kK40BzlWGYn4UnmMOQQ1odaO6qKDGPt4eY87QEhpqvAysfVef1XO+g1zW2Bx73k7spWIiIyAEWCwQGmY+weO+c0+02axPKi8wmE7fLXD3X83CZwaPa+4M+d1WYn5cXHdQM5DRflzjNfi1BkRASbdZk5O2APZvNeUwqSg6Uw3CZ4cbXAedI7GGVo4mizJDirmxmqmpuclV+L0ERlUOdW5nHeEKSHYbfbx7vAwoWIiLSuKxWc7htU3O7a/mlXMvritID7ytKzWMtlgPDgS1WwGIGm/wsM7gU7asMYCFmU0xFqfl5WaH5qHpdXnzQ9UoPut5B2wx39XIfOpqoLvk76/5s2J3H9NUdCwULERHxT1YrWB2VzRvNmNt1INS4yswmpqo+I+VF1ZtsrFXPVrPGpmqYc3lR9dDkw+HHRxUsXn31VZ577jmysrLo06cPr7zyCoMH17HgkIiIiNTNagNrsFnzAd5rgvKRBg9S/uSTT7jnnnuYOHEiy5cvp0+fPowePZqcnJzGKJ+IiIgcRxocLF544QVuuOEGxo8fT48ePXjjjTcICQnhnXfeaYzyiYiIyHGkQcGirKyMZcuWMWrUqAMnsFoZNWoUCxcurPWY0tJS8vLyqj1ERETEPzUoWOzZsweXy0Xr1q2rbW/dujVZWVm1HjNp0iQiIyM9j+Tk5KMvrYiIiDRrjT4R/EMPPYTT6fQ8tm8/wvAZEREROW41aFRIbGwsNpuN7Ozsatuzs7NJSEio9RiHw4HD0cyH+oiIiIhXNKjGwm63M2DAAH788UfPNrfbzY8//siQIUO8XjgRERE5vjR4Hot77rmHcePGMXDgQAYPHsyLL75IYWEh48ePb4zyiYiIyHGkwcHiz3/+M7t37+axxx4jKyuLvn378t1339Xo0CkiIiItj8UwDKMpL5iXl0dkZCROp5OIiIimvLSIiIgcpfr+/m70USEiIiLScihYiIiIiNcoWIiIiIjXNPmy6VVdOjS1t4iIyPGj6vf2kbpmNnmwyM/PB9DU3iIiIseh/Px8IiMj6/y8yUeFuN1udu7cSXh4OBaLxWvnzcvLIzk5me3bt7fY0SYt/TvQ/bfs+wd9By39/kHfQWPev2EY5Ofn06ZNG6zWuntSNHmNhdVqpW3bto12/oiIiBb5w3Swlv4d6P5b9v2DvoOWfv+g76Cx7v9wNRVV1HlTREREvEbBQkRERLzGb4KFw+Fg4sSJLXol1Zb+Hej+W/b9g76Dln7/oO+gOdx/k3feFBEREf/lNzUWIiIi4nsKFiIiIuI1ChYiIiLiNQoWIiIi4jUKFiIiIuI1fhMsXn31VTp06EBQUBAnnngiS5Ys8XWRGsWkSZMYNGgQ4eHhxMfHc9FFF7Fhw4Zq+5SUlDBhwgRatWpFWFgYl156KdnZ2T4qceN69tlnsVgs3HXXXZ5tLeH+d+zYwZVXXkmrVq0IDg6md+/e/Pbbb57PDcPgscceIzExkeDgYEaNGsWmTZt8WGLvcblcPProo6SkpBAcHEynTp146qmnqi2M5G/3//PPP3P++efTpk0bLBYLX375ZbXP63O/+/btY+zYsURERBAVFcV1111HQUFBE97F0Tvc/ZeXl/PAAw/Qu3dvQkNDadOmDVdffTU7d+6sdg5/vf9D3XzzzVgsFl588cVq25vy/v0iWHzyySfcc889TJw4keXLl9OnTx9Gjx5NTk6Or4vmdfPmzWPChAksWrSI2bNnU15ezplnnklhYaFnn7vvvpuvv/6aadOmMW/ePHbu3Mkll1ziw1I3jqVLl/Lmm29ywgknVNvu7/e/f/9+hg0bRmBgILNmzWLt2rX84x//IDo62rPP3//+d15++WXeeOMNFi9eTGhoKKNHj6akpMSHJfeOyZMn8/rrr/Ovf/2LdevWMXnyZP7+97/zyiuvePbxt/svLCykT58+vPrqq7V+Xp/7HTt2LGvWrGH27NnMnDmTn3/+mRtvvLGpbuGYHO7+i4qKWL58OY8++ijLly/niy++YMOGDVxwwQXV9vPX+z/Y9OnTWbRoEW3atKnxWZPev+EHBg8ebEyYMMHz3uVyGW3atDEmTZrkw1I1jZycHAMw5s2bZxiGYeTm5hqBgYHGtGnTPPusW7fOAIyFCxf6qphel5+fb6SmphqzZ882hg8fbtx5552GYbSM+3/ggQeMk08+uc7P3W63kZCQYDz33HOebbm5uYbD4TA++uijpihiozr33HONa6+9ttq2Sy65xBg7dqxhGP5//4Axffp0z/v63O/atWsNwFi6dKlnn1mzZhkWi8XYsWNHk5XdGw69/9osWbLEAIz09HTDMFrG/WdmZhpJSUnG6tWrjfbt2xv//Oc/PZ819f0f9zUWZWVlLFu2jFGjRnm2Wa1WRo0axcKFC31YsqbhdDoBiImJAWDZsmWUl5dX+z66detGu3bt/Or7mDBhAueee261+4SWcf8zZsxg4MCBXHbZZcTHx9OvXz/efvttz+dpaWlkZWVV+w4iIyM58cQT/eI7GDp0KD/++CMbN24E4I8//mD+/PmcffbZgP/f/6Hqc78LFy4kKiqKgQMHevYZNWoUVquVxYsXN3mZG5vT6cRisRAVFQX4//273W6uuuoq7rvvPnr27Fnj86a+/yZf3dTb9uzZg8vlonXr1tW2t27dmvXr1/uoVE3D7XZz1113MWzYMHr16gVAVlYWdrvd8xeqSuvWrcnKyvJBKb3v448/Zvny5SxdurTGZy3h/rdu3crrr7/OPffcw8MPP8zSpUu54447sNvtjBs3znOftf2d8Ifv4MEHHyQvL49u3bphs9lwuVw8/fTTjB07FsDv7/9Q9bnfrKws4uPjq30eEBBATEyM330nJSUlPPDAA1xxxRWe1T39/f4nT55MQEAAd9xxR62fN/X9H/fBoiWbMGECq1evZv78+b4uSpPZvn07d955J7NnzyYoKMjXxfEJt9vNwIEDeeaZZwDo168fq1ev5o033mDcuHE+Ll3j+/TTT/nggw/48MMP6dmzJytWrOCuu+6iTZs2LeL+pW7l5eWMGTMGwzB4/fXXfV2cJrFs2TJeeuklli9fjsVi8XVxAD/ovBkbG4vNZqvR6z87O5uEhAQflarx3XbbbcycOZM5c+bQtm1bz/aEhATKysrIzc2ttr+/fB/Lli0jJyeH/v37ExAQQEBAAPPmzePll18mICCA1q1b+/X9AyQmJtKjR49q27p3705GRgaA5z799e/Efffdx4MPPsjll19O7969ueqqq7j77ruZNGkS4P/3f6j63G9CQkKNzuwVFRXs27fPb76TqlCRnp7O7NmzPbUV4N/3/8svv5CTk0O7du08/yamp6fz17/+lQ4dOgBNf//HfbCw2+0MGDCAH3/80bPN7Xbz448/MmTIEB+WrHEYhsFtt93G9OnT+emnn0hJSan2+YABAwgMDKz2fWzYsIGMjAy/+D5GjhzJqlWrWLFihecxcOBAxo4d63ntz/cPMGzYsBpDjDdu3Ej79u0BSElJISEhodp3kJeXx+LFi/3iOygqKsJqrf5Pl81mw+12A/5//4eqz/0OGTKE3Nxcli1b5tnnp59+wu12c+KJJzZ5mb2tKlRs2rSJH374gVatWlX73J/v/6qrrmLlypXV/k1s06YN9913H99//z3gg/v3endQH/j4448Nh8NhTJ061Vi7dq1x4403GlFRUUZWVpavi+Z1t9xyixEZGWnMnTvX2LVrl+dRVFTk2efmm2822rVrZ/z000/Gb7/9ZgwZMsQYMmSID0vduA4eFWIY/n//S5YsMQICAoynn37a2LRpk/HBBx8YISEhxvvvv+/Z59lnnzWioqKMr776yli5cqVx4YUXGikpKUZxcbEPS+4d48aNM5KSkoyZM2caaWlpxhdffGHExsYa999/v2cff7v//Px84/fffzd+//13AzBeeOEF4/fff/eMeqjP/Z511llGv379jMWLFxvz5883UlNTjSuuuMJXt9Qgh7v/srIy44ILLjDatm1rrFixotq/i6WlpZ5z+Ov91+bQUSGG0bT37xfBwjAM45VXXjHatWtn2O12Y/DgwcaiRYt8XaRGAdT6mDJlimef4uJi49ZbbzWio6ONkJAQ4+KLLzZ27drlu0I3skODRUu4/6+//tro1auX4XA4jG7duhlvvfVWtc/dbrfx6KOPGq1btzYcDocxcuRIY8OGDT4qrXfl5eUZd955p9GuXTsjKCjI6Nixo/HII49U+yXib/c/Z86cWv/ejxs3zjCM+t3v3r17jSuuuMIICwszIiIijPHjxxv5+fk+uJuGO9z9p6Wl1fnv4pw5czzn8Nf7r01twaIp799iGAdNVyciIiJyDI77PhYiIiLSfChYiIiIiNcoWIiIiIjXKFiIiIiI1yhYiIiIiNcoWIiIiIjXKFiIiIiI1yhYiIiIiNcoWIiIiIjXKFiIiIiI1yhYiIiIiNf8P09nsLxLVQddAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Funções para preparar novos textos e gerar resumos"
      ],
      "metadata": {
        "id": "eB9bjRr_x2DJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "def preparar_texto_para_inferencia(texto, dict_token2id, max_len_text):\n",
        "    \"\"\"\n",
        "    Converte um texto (string) em uma sequência de IDs com padding,\n",
        "    seguindo o mesmo pré-processamento feito no treino.\n",
        "    \"\"\"\n",
        "    # 1. Tokeniza, adiciona <start> e <end>, e coloca tudo em minúsculo\n",
        "    tokens = ['<start>'] + word_tokenize(texto.lower()) + ['<end>']\n",
        "\n",
        "    # 2. Converte tokens em IDs usando seu vocabulário\n",
        "    token_ids = [dict_token2id.get(token, dict_token2id['<unk>']) for token in tokens]\n",
        "\n",
        "    # 3. Ajusta a sequência ao limite, mantendo <end> no final\n",
        "    end_token = dict_token2id['<end>']\n",
        "    if len(token_ids) > max_len_text:\n",
        "        if end_token in token_ids[:max_len_text]:\n",
        "            token_ids = token_ids[:max_len_text]\n",
        "        else:\n",
        "            token_ids = token_ids[:max_len_text-1] + [end_token]\n",
        "\n",
        "    # 4. Aplica padding para garantir o shape correto\n",
        "    token_ids_padded = pad_sequences([token_ids], maxlen=max_len_text, padding='post')\n",
        "\n",
        "    return token_ids_padded"
      ],
      "metadata": {
        "id": "QQ3V6ewBUgqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_transformer(input_seq, max_len=50):\n",
        "    # Começa com o token <start>\n",
        "    decoded_sentence = [dict_token2id['<start>']]\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        decoder_input = np.array([decoded_sentence])  # (1, current_length)\n",
        "\n",
        "        # Previsão com input do encoder e sequência parcial do decoder\n",
        "        preds = model.predict([input_seq, decoder_input], verbose=0)\n",
        "\n",
        "        next_token = np.argmax(preds[0, -1, :])\n",
        "        next_word = id2token.get(next_token, '<unk>')\n",
        "\n",
        "        if next_word == '<end>':\n",
        "            break\n",
        "\n",
        "        decoded_sentence.append(next_token)\n",
        "\n",
        "    decoded_words = [id2token.get(i, '') for i in decoded_sentence[1:]]  # remove <start>\n",
        "    return ' '.join(decoded_words)\n"
      ],
      "metadata": {
        "id": "zgwS4rVj03XA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_transformer_sampling(input_seq, max_len=50, top_k=5):\n",
        "    decoded_sentence = [dict_token2id['<start>']]\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        decoder_input = np.array([decoded_sentence])\n",
        "\n",
        "        # Gera a distribuição de probabilidade para o próximo token\n",
        "        preds = model.predict([input_seq, decoder_input], verbose=0)\n",
        "        logits = preds[0, -1, :]  # última posição da sequência\n",
        "\n",
        "        # Pega os top_k tokens com maior probabilidade\n",
        "        top_k_indices = np.argpartition(logits, -top_k)[-top_k:]\n",
        "        top_k_probs = logits[top_k_indices]\n",
        "        top_k_probs = np.exp(top_k_probs) / np.sum(np.exp(top_k_probs))  # softmax normalizado\n",
        "\n",
        "        # Escolhe aleatoriamente entre os top_k\n",
        "        next_token = np.random.choice(top_k_indices, p=top_k_probs)\n",
        "\n",
        "        next_word = id2token.get(next_token, '<unk>')\n",
        "        if next_word == '<end>':\n",
        "            break\n",
        "\n",
        "        decoded_sentence.append(next_token)\n",
        "\n",
        "    decoded_words = [id2token.get(i, '') for i in decoded_sentence[1:]]  # remove <start>\n",
        "    return ' '.join(decoded_words)"
      ],
      "metadata": {
        "id": "nb-6nFeITYwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import heapq\n",
        "\n",
        "def decode_transformer_beam_search(input_seq, max_len=50, beam_width=3):\n",
        "    start_token_id = dict_token2id['<start>']\n",
        "    end_token_id = dict_token2id['<end>']\n",
        "\n",
        "    # Beam é uma lista de tuplas: (pontuação_log, sequência)\n",
        "    beam = [(0.0, [start_token_id])]\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        new_beam = []\n",
        "\n",
        "        for score, seq in beam:\n",
        "            if seq[-1] == end_token_id:\n",
        "                # Se já terminou, mantém como está\n",
        "                new_beam.append((score, seq))\n",
        "                continue\n",
        "\n",
        "            decoder_input = np.array([seq])\n",
        "            preds = model.predict([input_seq, decoder_input], verbose=0)\n",
        "            probs = preds[0, -1, :]  # últimas probabilidades\n",
        "\n",
        "            # Pegamos os top beam_width candidatos\n",
        "            top_ids = np.argsort(probs)[-beam_width:]\n",
        "\n",
        "            for token_id in top_ids:\n",
        "                token_prob = probs[token_id]\n",
        "                if token_prob > 0:\n",
        "                    # Calcula novo score (soma de log-probs)\n",
        "                    new_score = score + np.log(token_prob)\n",
        "                    new_seq = seq + [token_id]\n",
        "                    new_beam.append((new_score, new_seq))\n",
        "\n",
        "        # Seleciona os beam_width melhores candidatos\n",
        "        beam = sorted(new_beam, key=lambda x: x[0], reverse=True)[:beam_width]\n",
        "\n",
        "    # Pega a sequência com maior pontuação\n",
        "    final_seq = beam[0][1]\n",
        "\n",
        "    # Converte para texto (pulando o <start> e parando no <end>)\n",
        "    decoded_tokens = []\n",
        "    for token_id in final_seq[1:]:  # pula <start>\n",
        "        if token_id == end_token_id:\n",
        "            break\n",
        "        decoded_tokens.append(id2token.get(token_id, ''))\n",
        "\n",
        "    return ' '.join(decoded_tokens)\n"
      ],
      "metadata": {
        "id": "w5wA0cl2U9tc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testando o modelo"
      ],
      "metadata": {
        "id": "0Z441Q6Syq6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_seq = X_encoder[7].reshape(1, -1)  # Garante que está no formato (1, sequência)\n",
        "pred_summary = decode_transformer(input_seq, 50)  # Função de geração com Transformer\n",
        "pred_summary_2 = decode_transformer_sampling(input_seq, 50)  # Função de geração com Transformer com sampling\n",
        "pred_summary_3 = decode_transformer_beam_search(input_seq, 50)  # Função de geração com Transformer com beam search\n",
        "\n",
        "print('Texto Original:')\n",
        "for id in X_encoder[7]:\n",
        "    print(id2token[id], end=' ')\n",
        "\n",
        "print('\\nResumo Original:')\n",
        "for id in y_decoder_input[7]:\n",
        "    print(id2token[id], end=' ')\n",
        "\n",
        "print('\\nResumo Gerado:')\n",
        "print(pred_summary)\n",
        "\n",
        "print('\\nResumo Gerado com Sampling:')\n",
        "print(pred_summary_2)\n",
        "\n",
        "print('\\nResumo Gerado com Beam Search:')\n",
        "print(pred_summary_3)\n"
      ],
      "metadata": {
        "id": "cMoyM0-xyrfi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51fdf60e-2f1c-4333-e0c0-cb772cb8cbad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Texto Original:\n",
            "<start> kandahar , afghanistan ( cnn ) -- the soldiers had barely arrived in iraq before they got new orders -- get ready for afghanistan . a soldier waits in baghdad for a flight to his new mission in kandahar . the 4th engineer battalion out of colorado springs , colorado , deployed to camp victory near baghdad in mid-february . two weeks after the unit began actually going out on operations in iraq , it was ordered to redeploy to kandahar in afghanistan . the soldiers had n't even finished painting their emblem outside their tactical operations command when the move began . but even as he walked through the stripped-down post , battalion commander lt. col. kevin landers could not hold back his excitement . `` the president has asked our military and our country to shift the focus and bolster the effort in afghanistan , and we are really spearheading some of that effort , so of course there is some excitement here , '' he said outside a building being cleared out . the move put a strain on this battalion , which specializes in route clearance , or finding and destroying land mines and bombs on roads to make them safe for travel . watch soldiers leave iraq , arrive in afghanistan » . `` yes , it is hard work , '' said pfc . kimble han , sweat pouring down his face as he pulled out a sandbag foundation for a tent he and colleagues had put out only weeks before . `` but i believe we have trained well and are prepared for the new mission in afghanistan . '' the battlefield in afghanistan is very different than iraq . `` in iraq you are looking at more close-quarters combat in an urban environment , but in afghanistan the area is only sparsely populated and we are looking at much more of a linear battlefield , '' said lt. matthew fitzgibbon . that means the soldiers will probably be engaged in longer distance firefights while on their patrols and their training in baghdad before the deployment mirrored that . the troops spent extra hours on the shooting range , recalibrating their weapons and testing different optics . `` no matter who the enemy is , we will bring a bigger fight , '' one soldier said loading his weapon . as the united states shifts its focus from iraq to afghanistan , the military has deemed route clearance so important to the operations in the kandahar area that it is airlifting the entire battalion to the new battlefield . the move poses huge logistical challenges to the army and especially the air force . between 50 and 70 gigantic c-17 cargo planes are necessary to transport dozens of heavy armored mine-resistant vehicles , containers and pallets -- all this as the air force 's capabilities are strained due to regular combat operations . many flights are delayed , canceled , rescheduled <end> \n",
            "Resumo Original:\n",
            "<start> troops had n't even finished painting their emblem when they got orders to move . redeployment put strain on battalion , trained to clear mines and bombs from roads . cnn traveled with troops as they flew from one war zone to the next . soldiers say they are ready for the new mission in the new battlefield \n",
            "Resumo Gerado:\n",
            "troops had n't even finished painting their emblem when they got orders to move . redeployment put strain on battalion , trained to clear mines and bombs from roads . cnn traveled with troops as they flew from one war zone to the next . soldiers say they are ready\n",
            "\n",
            "Resumo Gerado com Sampling:\n",
            "last battle valery breyer , for comrade spent the permission since they got idea with planes to climb . they have visited new mh17 tragedy . he leaves them around . vice president picks six astronauts who travels to be left a group to hold their equipment .\n",
            "\n",
            "Resumo Gerado com Beam Search:\n",
            "troops had n't even finished painting their emblem when they got orders to move . redeployment put strain on battalion , trained to clear mines and bombs from roads . cnn traveled with troops as they flew from one war zone to the next . soldiers say they are ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "novo_texto = \"Christopher Nolan’s Interstellar is a visually stunning, emotionally profound, and intellectually ambitious film that delves into the mysteries of space, time, and human resilience. Released in 2014, the film presents a future where Earth is no longer able to sustain life. Dust storms ravage the land, crops are failing, and the human population is slowly dwindling. Amidst this global crisis, a team of astronauts embarks on a journey through a wormhole in search of a new habitable planet. At the heart of the story is Cooper, a former NASA pilot turned farmer, played by Matthew McConaughey. He is a father torn between staying with his children and the urgent need to help save humanity. When the opportunity arises to join a secret space mission, he reluctantly accepts, leaving behind his young daughter Murph, whose emotional connection to her father drives much of the film’s narrative power. One of Interstellar's most compelling elements is its exploration of time. Due to the effects of relativity, time passes differently for those traveling near a black hole compared to those remaining on Earth. This results in heartbreaking consequences, particularly for Cooper, who watches years pass by for his children while only experiencing hours or days himself. The film’s treatment of time is both scientifically inspired and deeply poetic, raising profound questions about memory, aging, and the nature of human connection. The science behind the film is grounded in real physics, thanks in part to the involvement of theoretical physicist Kip Thorne, who served as an executive producer and scientific consultant. Concepts such as wormholes, time dilation, and gravitational anomalies are woven into the story in a way that challenges audiences without alienating them. While some liberties are taken for dramatic effect, the film remains one of the most scientifically thoughtful space adventures in cinematic history. Visually, Interstellar is a masterpiece. The depiction of the black hole Gargantua, with its glowing accretion disk, has become iconic. The barren, icy planets, the colossal waves on a water world, and the infinite expanse of space are rendered with breathtaking realism. Hans Zimmer’s haunting, organ-driven score adds emotional depth and grandeur to the visuals, heightening the film’s sense of awe and existential wonder. Beyond its scientific and visual achievements, Interstellar is ultimately a human story. It is about love as a force that transcends dimensions, about sacrifice, hope, and the indomitable will to survive. The relationship between Cooper and Murph forms the emotional core of the film, culminating in a powerful reunion that speaks to the enduring bond between parent and child. In conclusion, Interstellar is not just a science fiction film; it is a cinematic experience that challenges the mind and stirs the soul. With its blend of cutting-edge science, philosophical inquiry, and emotional storytelling, it continues to captivate and inspire audiences around the world.\"\n",
        "texto_tokenizado = preparar_texto_para_inferencia(novo_texto, dict_token2id, 500)\n",
        "print(texto_tokenizado, len(texto_tokenizado[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-CT-ljE-flJ",
        "outputId": "7aa1eac4-2cc8-4c19-b13b-cf1d62eec7cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[     1   2628  10187    145    146  31439     16     29  18228   5656\n",
            "      53  16217  17107     53     34  39161  13850   2935     13  51808\n",
            "      40     17  15122     31   4560     53    412     53     34   8010\n",
            "   10381     23   3090     42    165     53     17   2935   9056     29\n",
            "    2470    171    674     16    468   1212    564     83  13480    497\n",
            "      23   9817   6515 106128     17   1291     53  30100    215   8991\n",
            "      53     34     17   8010   1036     16   5408  15768     23  13849\n",
            "      21   1128   6167     53     29    143     31   7542  33052     72\n",
            "      29   5803    359     29 140565     42    489     31     29    109\n",
            "   26056   3309     23    137     17   1689     31     17   1841     16\n",
            "   14716     53     29      2  16121  12895   2465   2587     53    779\n",
            "      93   1323  12182     23    185     16     29    334  19523     76\n",
            "     987     67    134    561     34     17   8788   1808     83    629\n",
            "    1965   6895     23    346     17   2077  25753     83   2744     29\n",
            "   10550   4560   1242     53    185  26111   3979     53    333   1695\n",
            "     134    370   2314      0     53   1517   2392   2809     83    840\n",
            "     334  12150   1091     31     17   2935    145    146   5415   1597\n",
            "      23     88     31  31439    214    991  20604   3998     16    927\n",
            "    1496     31    412     23   1373     83     17   9606     31  31567\n",
            "      53    412   1879  10245     27    726   5222   1249     29   1795\n",
            "    9104   2891     83    726  10401     72    674     23     21   3223\n",
            "      42   6786   3524     53   3583     27  14716     53    745   4525\n",
            "     467   3432     93     27    134    561    888   1140  12712   1335\n",
            "     414    212   3743     23     17   2935    145    146   5402     31\n",
            "     412     16    560  23313   2265     34   2236  22532     53   3679\n",
            "   17107   5107    179   6852     53   6999     53     34     17   8236\n",
            "      31   8010   2809     23     17   1569   1695     17   2935     16\n",
            "   18027     42   1600   4553     53   3479     42    938     83     17\n",
            "    7750     31  16580   7648   8780  41559     53    745   4375    200\n",
            "     111   4015   8489     34  17320  15143     23  11141   1804    200\n",
            "   37826     53    412  93800     53     34  27857  49793    215   7041\n",
            "      40     17   1841     42     29    550     13   1134  24151   1038\n",
            "   29077     82     23    888    493  23687    215    868     27   4501\n",
            "    4996     53     17   2935    522     88     31     17    991  23313\n",
            "   13107   4560  26107     42  33387    810     23  18228     53  31439\n",
            "      16     29  17577     23     17   2238     31     17   1795   9104\n",
            "       0     53     67    927  39238      0  12908     53      8    505\n",
            "    1812     23     17  24357     53   2114  16099     53     17  25200\n",
            "    7721     72     29   1668    168     53     34     17   7704  25197\n",
            "      31   4560    215  18103     67  31186  47687     23  23643  23644\n",
            "     145    146  23662     53      0    292   3092   2392   4545     34\n",
            "   38825     83     17  36995     53  49806     17   2935    145    146\n",
            "    5881     31  12996     34  63784   4153     23   6067    927  17320\n",
            "      34   8795    803     53  31439     16   6897     29   8010   1841\n",
            "      23    389     16    179    595    200     29   1357     13  61378\n",
            "   29547     53    179  12986     53   1394     53     34     17  49228\n",
            "     131     83   9552     23     17   2418     76  14716     34      0\n",
            "    4093     17   2392   8992     31     17   2935     53  43870     42\n",
            "      29   1202  21395     13   6905     83     17   6412   7408     76\n",
            "    2326     34    906     23     42   7670     53  31439     16    128]] 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resumo = decode_transformer(texto_tokenizado, 50)\n",
        "print(\"texto original:\")\n",
        "print(novo_texto)\n",
        "print(\"\\nresumo gerado:\")\n",
        "print(resumo)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5EOooHN_jkh",
        "outputId": "c2c523b1-49a8-4409-f7bb-9188effe6c2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "texto original:\n",
            "Christopher Nolan’s Interstellar is a visually stunning, emotionally profound, and intellectually ambitious film that delves into the mysteries of space, time, and human resilience. Released in 2014, the film presents a future where Earth is no longer able to sustain life. Dust storms ravage the land, crops are failing, and the human population is slowly dwindling. Amidst this global crisis, a team of astronauts embarks on a journey through a wormhole in search of a new habitable planet. At the heart of the story is Cooper, a former NASA pilot turned farmer, played by Matthew McConaughey. He is a father torn between staying with his children and the urgent need to help save humanity. When the opportunity arises to join a secret space mission, he reluctantly accepts, leaving behind his young daughter Murph, whose emotional connection to her father drives much of the film’s narrative power. One of Interstellar's most compelling elements is its exploration of time. Due to the effects of relativity, time passes differently for those traveling near a black hole compared to those remaining on Earth. This results in heartbreaking consequences, particularly for Cooper, who watches years pass by for his children while only experiencing hours or days himself. The film’s treatment of time is both scientifically inspired and deeply poetic, raising profound questions about memory, aging, and the nature of human connection. The science behind the film is grounded in real physics, thanks in part to the involvement of theoretical physicist Kip Thorne, who served as an executive producer and scientific consultant. Concepts such as wormholes, time dilation, and gravitational anomalies are woven into the story in a way that challenges audiences without alienating them. While some liberties are taken for dramatic effect, the film remains one of the most scientifically thoughtful space adventures in cinematic history. Visually, Interstellar is a masterpiece. The depiction of the black hole Gargantua, with its glowing accretion disk, has become iconic. The barren, icy planets, the colossal waves on a water world, and the infinite expanse of space are rendered with breathtaking realism. Hans Zimmer’s haunting, organ-driven score adds emotional depth and grandeur to the visuals, heightening the film’s sense of awe and existential wonder. Beyond its scientific and visual achievements, Interstellar is ultimately a human story. It is about love as a force that transcends dimensions, about sacrifice, hope, and the indomitable will to survive. The relationship between Cooper and Murph forms the emotional core of the film, culminating in a powerful reunion that speaks to the enduring bond between parent and child. In conclusion, Interstellar is not just a science fiction film; it is a cinematic experience that challenges the mind and stirs the soul. With its blend of cutting-edge science, philosophical inquiry, and emotional storytelling, it continues to captivate and inspire audiences around the world.\n",
            "\n",
            "resumo gerado:\n",
            "he has grown by many of stars . they lead to breakthrough models including 3d printer . equally as likely to discover what and full of `` whole similar to paddle back on earth as normal models as normal models '' <end> , from kent always written to have only\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "novo_texto = \"Bitcoin is a decentralized digital currency that has transformed the way people think about money, finance, and trust. Introduced in 2009 by the pseudonymous creator Satoshi Nakamoto, Bitcoin emerged in the aftermath of the 2008 financial crisis as a response to the perceived flaws in the traditional banking system. It operates on a peer-to-peer network, allowing users to send and receive payments without the need for intermediaries such as banks or governments. At its core, Bitcoin relies on blockchain technology—a distributed public ledger that records every transaction ever made on the network. This ledger is maintained by a decentralized network of computers (called nodes) around the world. Each transaction is verified by miners, who use computational power to solve complex mathematical puzzles. Once a transaction is validated, it is added to a block, and that block is appended to the blockchain. One of the key features of Bitcoin is its limited supply. Unlike fiat currencies, which can be printed at will by central banks, Bitcoin has a maximum supply of 21 million coins. This scarcity, combined with increasing demand, has driven significant price volatility. Over the years, Bitcoin has experienced dramatic price swings—reaching all-time highs and crashing just as quickly. While some investors see this volatility as a risk, others view it as an opportunity. Bitcoin's decentralized nature makes it resistant to censorship and government control. Transactions are pseudonymous, meaning users can send and receive Bitcoin without revealing their real identities. This has led to concerns about illegal use cases, such as money laundering and black-market transactions. However, Bitcoin is also used for legitimate purposes, including remittances, online purchases, and as a hedge against inflation in countries with unstable currencies. Another important aspect of Bitcoin is its role as “digital gold.” Just as gold is considered a store of value, many investors believe Bitcoin serves a similar purpose in the digital realm. It is borderless, secure, and not tied to any specific government or economy. As a result, institutions and hedge funds have increasingly added Bitcoin to their portfolios as part of a diversified investment strategy. Over time, Bitcoin has sparked the creation of thousands of other cryptocurrencies, collectively known as altcoins. Some of these attempt to improve on Bitcoin’s technology, while others serve entirely different purposes—from smart contracts to decentralized finance (DeFi). Nevertheless, Bitcoin remains the most well-known and widely adopted cryptocurrency. Despite its growing popularity, Bitcoin faces several challenges. These include scalability issues, high energy consumption related to mining, and regulatory uncertainty in many countries. Developers and community members continue to work on solutions, such as the Lightning Network, which aims to make transactions faster and cheaper. In conclusion, Bitcoin represents a revolutionary shift in the way we understand and use money. It has opened the door to a more transparent, decentralized, and inclusive financial system. While it is still evolving, Bitcoin has already made a lasting impact on the global economy and will likely continue to shape the future of finance for years to come.\"\n",
        "texto_tokenizado = preparar_texto_para_inferencia(novo_texto, dict_token2id, 500)\n",
        "\n",
        "resumo = decode_transformer(texto_tokenizado, 50)\n",
        "resumo_sampling = decode_transformer_sampling(texto_tokenizado, 50)\n",
        "resumo_beam_search = decode_transformer_beam_search(texto_tokenizado, 50)\n",
        "\n",
        "print(\"texto original:\")\n",
        "print(novo_texto)\n",
        "print(\"\\nresumo gerado:\")\n",
        "print(resumo)\n",
        "print(\"\\nresumo gerado com sampling:\")\n",
        "print(resumo_sampling)\n",
        "print(\"\\nresumo gerado com beam search:\")\n",
        "print(resumo_beam_search)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdvhkKEOA053",
        "outputId": "fe431636-6fae-446f-dc4f-8cf77c6ad6fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "texto original:\n",
            "Bitcoin is a decentralized digital currency that has transformed the way people think about money, finance, and trust. Introduced in 2009 by the pseudonymous creator Satoshi Nakamoto, Bitcoin emerged in the aftermath of the 2008 financial crisis as a response to the perceived flaws in the traditional banking system. It operates on a peer-to-peer network, allowing users to send and receive payments without the need for intermediaries such as banks or governments. At its core, Bitcoin relies on blockchain technology—a distributed public ledger that records every transaction ever made on the network. This ledger is maintained by a decentralized network of computers (called nodes) around the world. Each transaction is verified by miners, who use computational power to solve complex mathematical puzzles. Once a transaction is validated, it is added to a block, and that block is appended to the blockchain. One of the key features of Bitcoin is its limited supply. Unlike fiat currencies, which can be printed at will by central banks, Bitcoin has a maximum supply of 21 million coins. This scarcity, combined with increasing demand, has driven significant price volatility. Over the years, Bitcoin has experienced dramatic price swings—reaching all-time highs and crashing just as quickly. While some investors see this volatility as a risk, others view it as an opportunity. Bitcoin's decentralized nature makes it resistant to censorship and government control. Transactions are pseudonymous, meaning users can send and receive Bitcoin without revealing their real identities. This has led to concerns about illegal use cases, such as money laundering and black-market transactions. However, Bitcoin is also used for legitimate purposes, including remittances, online purchases, and as a hedge against inflation in countries with unstable currencies. Another important aspect of Bitcoin is its role as “digital gold.” Just as gold is considered a store of value, many investors believe Bitcoin serves a similar purpose in the digital realm. It is borderless, secure, and not tied to any specific government or economy. As a result, institutions and hedge funds have increasingly added Bitcoin to their portfolios as part of a diversified investment strategy. Over time, Bitcoin has sparked the creation of thousands of other cryptocurrencies, collectively known as altcoins. Some of these attempt to improve on Bitcoin’s technology, while others serve entirely different purposes—from smart contracts to decentralized finance (DeFi). Nevertheless, Bitcoin remains the most well-known and widely adopted cryptocurrency. Despite its growing popularity, Bitcoin faces several challenges. These include scalability issues, high energy consumption related to mining, and regulatory uncertainty in many countries. Developers and community members continue to work on solutions, such as the Lightning Network, which aims to make transactions faster and cheaper. In conclusion, Bitcoin represents a revolutionary shift in the way we understand and use money. It has opened the door to a more transparent, decentralized, and inclusive financial system. While it is still evolving, Bitcoin has already made a lasting impact on the global economy and will likely continue to shape the future of finance for years to come.\n",
            "\n",
            "resumo gerado:\n",
            "an files a phone wii u smile . the media outlets reveal that put on may . it 's the most prestigious story and developed a report .\n",
            "\n",
            "resumo gerado com sampling:\n",
            "roughly how thursday 's perpetrators recently filed arizona . there are plenty to adapt to its new story ; an ipad photographer remind the most notable launch . the u.s. counterparts asking product ; its battery its cooks meals , with . <unk>\n",
            "\n",
            "resumo gerado com beam search:\n",
            "an `` negro joins in 1971 to focus on such as chief executive of the 1980s . e-book form of agent says roy 's rights and stored . author says roy 's hugh bonneville have n't make content .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testando com dados do mesmo contexto"
      ],
      "metadata": {
        "id": "GQwsrcoQNysx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Removendo todas as amostras usadas no treinamento\n",
        "df_final_testes = df_final_testes.drop(df.index)\n",
        "\n",
        "print(df_final_testes.shape)\n",
        "print(df_final_testes.index)\n",
        "df_final_testes.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "-O3ph6RPNyVa",
        "outputId": "d22f1b52-59f4-4fd4-9b11-7bffd1bc0a2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(271971, 3)\n",
            "Index([     1,      3,      4,      5,      6,      7,      8,      9,     10,\n",
            "           11,\n",
            "       ...\n",
            "       311958, 311960, 311961, 311963, 311964, 311965, 311966, 311968, 311969,\n",
            "       311970],\n",
            "      dtype='int64', length=271971)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             article  \\\n",
              "1  Editor's note: In our Behind the Scenes series...   \n",
              "3  WASHINGTON (CNN) -- Doctors removed five small...   \n",
              "4  (CNN)  -- The National Football League has ind...   \n",
              "5  BAGHDAD, Iraq (CNN) -- Dressed in a Superman s...   \n",
              "6  BAGHDAD, Iraq (CNN) -- The women are too afrai...   \n",
              "\n",
              "                                             summary  \\\n",
              "1  Mentally ill inmates in Miami are housed on th...   \n",
              "3  Five small polyps found during procedure; \"non...   \n",
              "4  NEW: NFL chief, Atlanta Falcons owner critical...   \n",
              "5  Parents beam with pride, can't stop from smili...   \n",
              "6  Aid workers: Violence, increased cost of livin...   \n",
              "\n",
              "                                         id  \n",
              "1  ee8871b15c50d0db17b0179a6d2beab35065f1e9  \n",
              "3  24521a2abb2e1f5e34e6824e0f9e56904a2b0e88  \n",
              "4  7fe70cc8b12fab2d0a258fababf7d9c6b5e1262a  \n",
              "5  a1ebb8bb4d370a1fdf28769206d572be60642d70  \n",
              "6  7c0e61ac829a3b3b653e2e3e7536cc4881d1f264  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-031d5c25-9253-4daf-980c-b3ed6c95652f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article</th>\n",
              "      <th>summary</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Editor's note: In our Behind the Scenes series...</td>\n",
              "      <td>Mentally ill inmates in Miami are housed on th...</td>\n",
              "      <td>ee8871b15c50d0db17b0179a6d2beab35065f1e9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>WASHINGTON (CNN) -- Doctors removed five small...</td>\n",
              "      <td>Five small polyps found during procedure; \"non...</td>\n",
              "      <td>24521a2abb2e1f5e34e6824e0f9e56904a2b0e88</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(CNN)  -- The National Football League has ind...</td>\n",
              "      <td>NEW: NFL chief, Atlanta Falcons owner critical...</td>\n",
              "      <td>7fe70cc8b12fab2d0a258fababf7d9c6b5e1262a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>BAGHDAD, Iraq (CNN) -- Dressed in a Superman s...</td>\n",
              "      <td>Parents beam with pride, can't stop from smili...</td>\n",
              "      <td>a1ebb8bb4d370a1fdf28769206d572be60642d70</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>BAGHDAD, Iraq (CNN) -- The women are too afrai...</td>\n",
              "      <td>Aid workers: Violence, increased cost of livin...</td>\n",
              "      <td>7c0e61ac829a3b3b653e2e3e7536cc4881d1f264</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-031d5c25-9253-4daf-980c-b3ed6c95652f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-031d5c25-9253-4daf-980c-b3ed6c95652f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-031d5c25-9253-4daf-980c-b3ed6c95652f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-b948f1ff-e983-42fb-8acb-f837808a31b6\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b948f1ff-e983-42fb-8acb-f837808a31b6')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-b948f1ff-e983-42fb-8acb-f837808a31b6 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_final_testes"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "novo_texto = df_final_testes['article'][10]\n",
        "texto_tokenizado = preparar_texto_para_inferencia(novo_texto, dict_token2id, 500)\n",
        "\n",
        "resumo = decode_transformer(texto_tokenizado, 50)\n",
        "\n",
        "resumo_sampling = decode_transformer_sampling(texto_tokenizado, 50)\n",
        "\n",
        "resumo_beam_search = decode_transformer_beam_search(texto_tokenizado, 50)\n",
        "\n",
        "print(\"texto original:\")\n",
        "print(novo_texto)\n",
        "print(\"\\nresumo original:\")\n",
        "print(df_final_testes['summary'][10])\n",
        "print(\"\\nresumo gerado:\")\n",
        "print(resumo)\n",
        "print(\"\\nresumo gerado com sampling:\")\n",
        "print(resumo_sampling)\n",
        "print(\"\\nresumo gerado com beam search:\")\n",
        "print(resumo_beam_search)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xujqp7IFOaEk",
        "outputId": "657476be-f618-42f3-a7af-c7e0dceb03ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "texto original:\n",
            "WASHINGTON (CNN) -- As he awaits a crucial progress report on Iraq, President Bush will try to put a twist on comparisons of the war to Vietnam by invoking the historical lessons of that conflict to argue against pulling out. President Bush pauses Tuesday during a news conference at the  North American Leaders summit in Canada. On Wednesday in Kansas City, Missouri, Bush will tell members of the Veterans of Foreign Wars that \"then, as now, people argued that the real problem was America's presence and that if we would just withdraw, the killing would end,\" according to speech excerpts released Tuesday by the White House. \"Three decades later, there is a legitimate debate about how we got into the Vietnam War and how we left,\" Bush will say. \"Whatever your position in that debate, one unmistakable legacy of Vietnam is that the price of America's withdrawal was paid by millions of innocent citizens, whose agonies would add to our vocabulary new terms like 'boat people,' 're-education camps' and 'killing fields,' \" the president will say. The president will also make the argument that withdrawing from Vietnam emboldened today's terrorists by compromising U.S. credibility, citing a quote from al Qaeda leader Osama bin Laden that the American people would rise against the Iraq war the same way they rose against the war in Vietnam, according to the excerpts. \"Here at home, some can argue our withdrawal from Vietnam carried no price to American credibility, but the terrorists see things differently,\" Bush will say. On Tuesday, Democratic Senate Majority Leader Harry Reid said, \"President Bush's attempt to compare the war in Iraq to past military conflicts in East Asia ignores the fundamental difference between the two. Our nation was misled by the Bush Administration in an effort to gain support for the invasion of Iraq under false pretenses, leading to one of the worst foreign policy blunders in our history. \"While the President continues to stay-the-course with his failed strategy in Iraq, paid for by the taxpayers, American lives are being lost and there is still no political solution within the Iraqi government. It is time to change direction in Iraq, and Congress will again work to do so in the fall.\" The White House is billing the speech, along with another address next week to the American Legion, as an effort to \"provide broader context\" for the debate over the upcoming Iraq progress report by Gen. David Petraeus, the top U.S. military commander, and Ryan Crocker, the U.S. ambassador in Baghdad. President Bush has frequently asked lawmakers -- and the American people -- to withhold judgment on his troop \"surge\" in Iraq until the report comes out in September.  Watch Bush criticize the Iraqi government » . It is being closely watched on Capitol Hill, particularly by Republicans nervous about the political fallout from an increasingly unpopular war. Earlier this month, Defense Secretary Robert Gates said he would wait for the report before deciding when a drawdown of the 160,000 U.S. troops in Iraq might begin. Bush's speeches Wednesday and next week are the latest in a series of attempts by the White House to try to reframe the debate over Iraq, as public support for the war continues to sag. A recent CNN/Opinion Research Corporation poll found that almost two-thirds of Americans -- 64 percent -- now oppose the Iraq war, and 72 percent say that even if Petraeus reports progress, it won't change their opinion. The poll also found a great deal of skepticism about the report; 53 percent said they do not trust Petraeus to give an accurate assessment of the situation in Iraq. In addition to his analogy to Vietnam, Bush in Wednesday's speech will invoke other historical comparisons from Asia, including the U.S. defeat and occupation of Japan after World War II and the Korean War in the 1950s, according to the excerpts. \"In the aftermath of Japan's surrender, many thought it naive to help the Japanese transform themselves into a democracy. Then, as now, the critics argued that some people were simply not fit for freedom,\" Bush will say. \"Today, in defiance of the critics, Japan ... stands as one of the world's great free societies.\" Speaking about the Korean War, Bush will note that at the time \"critics argued that the war was futile, that we never should have sent our troops in, or that America's intervention was divisive here at home.\" \"While it is true that the Korean War had its share of challenges, America never broke its word,\" Bush will say. \"Without America's intervention during the war, and our willingness to stick with the South Koreans after the war, millions of South Koreans would now be living under a brutal and repressive regime.\" E-mail to a friend .\n",
            "\n",
            "resumo original:\n",
            "President Bush to address the Veterans of Foreign Wars on Wednesday .\n",
            "Bush to say that withdrawing from Vietnam emboldened today's terrorists .\n",
            "Speech will be latest White House attempt to try to reframe the debate over Iraq .\n",
            "\n",
            "resumo gerado:\n",
            "the obama is not only major cause in iraq and iraq , source of the political cause major cause in iraq , says . obama said on major depression act is not only major source of these issues asia and iraq has chemical weapons .\n",
            "\n",
            "resumo gerado com sampling:\n",
            "the obama reacts its `` spy who can only human regulation '' to put pressure over the political observers ' success in the speech convention against isis has nasa in isis , the house speaker and iraq . afghanistan and the political observers have previously only theory ?\n",
            "\n",
            "resumo gerado com beam search:\n",
            "the obama is not only major cause in iraq and iraq , source of the political economies . political concern the political observers believe in iraq has major cause in iraq and afghanistan 's nuclear weapons . the political cause marine corps is not only major cause in iraq and\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}